{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before Analysis..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFR을 선택하였습니다.\n",
      "Opening raw data file H:\\Mg_EEG\\edf_files\\정금례_7200_clean.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esin4\\AppData\\Local\\Temp\\ipykernel_13236\\1638311694.py:20: RuntimeWarning: This filename (H:\\Mg_EEG\\edf_files\\정금례_7200_clean.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  clean_data = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 1439800 =      0.000 ...  7199.000 secs\n",
      "Ready.\n",
      "Reading 0 ... 1439800  =      0.000 ...  7199.000 secs...\n",
      "fif 파일을 성공적으로 불러왔습니다: H:\\Mg_EEG\\edf_files\\정금례_7200_clean.fif\n",
      "TFR을 계산 중 입니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  18 | elapsed:  7.3min remaining: 11.5min\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  18 | elapsed:  7.4min remaining:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  18 | elapsed:  7.6min remaining:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:  7.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFR 계산이 완료되었습니다.\n",
      "TFR 파일이 성공적으로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from decimal import Decimal, getcontext\n",
    "import pandas as pd\n",
    "import ast\n",
    "import openpyxl as op\n",
    "\n",
    "# 분석대상 이름 입력\n",
    "name = input(\"분석대상 이름을 입력하세요.\")\n",
    "purpose = input(\"목적을 입력하세요. TFR or loading\")\n",
    "bad_channels_name = input(\"제거할 채널 이름을 입력하세요. 없으면 enter를 누르세요.\")\n",
    "\n",
    "if purpose == \"TFR\":\n",
    "    print(f\"TFR을 선택하였습니다.\")\n",
    "    # fif 파일 불러오기\n",
    "    file_path = rf'H:\\Mg_EEG\\edf_files\\{name}_7200_clean.fif'\n",
    "    clean_data = mne.io.read_raw_fif(file_path, preload=True)\n",
    "    print(f\"fif 파일을 성공적으로 불러왔습니다: {file_path}\")\n",
    "    \n",
    "    # Delete data for a specific channel\n",
    "    bad_channels_list = [channel.strip() for channel in bad_channels_name.split(',')]\n",
    "    clean_data.drop_channels(bad_channels_list)\n",
    "    \n",
    "    # Computing TFR\n",
    "    print(f\"TFR을 계산 중 입니다.\")\n",
    "    tfr = clean_data.compute_tfr(method='multitaper', freqs=np.arange(1, 31), tmin=0, tmax=7199, n_jobs=-1, reject_by_annotation=False)\n",
    "    print(f\"TFR 계산이 완료되었습니다.\")\n",
    "\n",
    "    # Saving TFR file\n",
    "    saving_path = rf'H:\\Mg_EEG\\tfr_files\\{name}_7200_tfr.h5'\n",
    "    tfr.save(saving_path, overwrite=True)\n",
    "    print(f\"TFR 파일이 성공적으로 저장되었습니다.\")\n",
    "\n",
    "    # Saving raw file for back-up\n",
    "    tfr_raw = tfr.copy()\n",
    "\n",
    "elif purpose == \"loading\":\n",
    "    print(f\"loading을 선택하였습니다.\")\n",
    "    # Loading saved TFR file\n",
    "    file_path = rf'H:\\Mg_EEG\\tfr_files\\{name}_7200_tfr.h5'\n",
    "    tfr = mne.time_frequency.read_tfrs(file_path)\n",
    "    print(f\"성공적으로 tfr 파일을 로딩하였습니다.\")\n",
    "\n",
    "    # Saving raw file for back-up\n",
    "    tfr_raw = tfr.copy()\n",
    "\n",
    "else:\n",
    "    print(\"올바른 값을 입력하시오\")\n",
    "    quit()\n",
    "\n",
    "def tfr_mean(tfr):\n",
    "    mean_electrode = np.mean(tfr.data, axis=0) # Averaging across electrode\n",
    "    mean_frequency = np.mean(mean_electrode, axis=0) # Averaging across frequency\n",
    "    return(mean_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw fif file 보고 싶다면 사용\n",
    "#clean_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터가 뭔가 이상할 때 리셋하는 복구 코드\n",
    "#tfr = tfr_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large_artifact 리스트:\n",
      "[(4804, 4847), (4881, 4886), (4962, 4969), (4978, 4982), (5025, 5027), (6847, 6849), (6887, 6896), (6901, 6905), (6918, 6922), (6930, 6939)]\n"
     ]
    }
   ],
   "source": [
    "# large artifact data load\n",
    "csv_file_path = r'C:\\Users\\esin4\\OneDrive\\바탕 화면\\Github\\Mg_infusion_coma\\large_artifact.csv'\n",
    "\n",
    "large_artifact_data = pd.read_csv(csv_file_path, encoding='utf-8-sig')\n",
    "\n",
    "# 입력한 이름이 데이터프레임에 존재하는지 확인하고 좌표 가져오기\n",
    "if name in large_artifact_data['Name'].values:\n",
    "    # 입력한 이름에 해당하는 데이터 가져오기\n",
    "    coordinates = large_artifact_data[large_artifact_data['Name'] == name]['Coordinates'].values[0]\n",
    "    \n",
    "    # 좌표가 'skip'이면 빈 리스트로 설정\n",
    "    if coordinates == 'skip':\n",
    "        large_artifact = []\n",
    "    else:\n",
    "        # 좌표 문자열을 리스트로 변환\n",
    "        import ast\n",
    "        large_artifact = ast.literal_eval(coordinates)\n",
    "else:\n",
    "    print(f\"{input_name}이(가) 데이터에 없습니다.\")\n",
    "    large_artifact = []\n",
    "\n",
    "# 결과 출력\n",
    "print(\"large_artifact 리스트:\")\n",
    "print(large_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석한 값 저장할 엑셀 파일\n",
    "wb = op.load_workbook(r\"C:\\Users\\esin4\\OneDrive\\바탕 화면\\Github\\Mg_infusion_coma\\Mg_infusion_data.xlsx\")\n",
    "row = int(input(\"데이터가 입력될 행을 입력하세요.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# independent t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정금례, independent t test\n",
      "mean_before : \n",
      " 5.508813512768684e-09\n",
      "mean_after : \n",
      " 1.1066684670646506e-08\n",
      "t_statistics : \n",
      " -433.73322068842236\n",
      "p-value: \n",
      " 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
      "effect size \n",
      " -0.44789287791773297\n"
     ]
    }
   ],
   "source": [
    "# Before vs After segmentation\n",
    "tfr_before = tfr.copy().crop(tmin=0, tmax=3600, include_tmax=False)\n",
    "tfr_after = tfr.copy().crop(tmin=3600, tmax=7199, include_tmax=False)\n",
    "\n",
    "# Averaging\n",
    "before_mean = tfr_mean(tfr_before)\n",
    "after_mean = tfr_mean(tfr_after)\n",
    "\n",
    "# Indexing about Large artifact\n",
    "before_idx = []\n",
    "after_idx = []\n",
    "\n",
    "for t_start, t_end in large_artifact:\n",
    "    if t_start < 3600 and t_end < 3600:\n",
    "        before_idx.extend(range(t_start*200, t_end*200))\n",
    "    elif t_start < 3600 and t_end >= 3600:\n",
    "        before_idx.extend(range(t_start*200, 3600*200))\n",
    "        after_idx.extend(range(0, (t_end-3600)*200))\n",
    "    else:\n",
    "        after_idx.extend(range((t_start-3600)*200, (t_end-3600)*200))\n",
    "\n",
    "# Removing Large artifacts\n",
    "before_mean_clean = np.delete(before_mean, before_idx)\n",
    "after_mean_clean = np.delete(after_mean, after_idx)\n",
    "\n",
    "# independent t-test\n",
    "# precision\n",
    "getcontext().prec = 50\n",
    "\n",
    "print(f\"{name}, independent t test\")\n",
    "# mean of before vs after\n",
    "mean_before = np.mean(before_mean_clean)\n",
    "mean_after = np.mean(after_mean_clean)\n",
    "print(\"mean_before : \\n\", mean_before)\n",
    "print(\"mean_after : \\n\", mean_after)\n",
    "\n",
    "# t-test\n",
    "t_stat, p_value = stats.ttest_ind(before_mean_clean, after_mean_clean)\n",
    "\n",
    "# print to decimal object\n",
    "p_value_decimal = Decimal(p_value)\n",
    "print (\"t_statistics : \\n\", t_stat)\n",
    "p_value_str = f\"{p_value_decimal:.100f}\"\n",
    "print(f\"p-value: \\n {p_value_str}\")\n",
    "\n",
    "# Define Cohens'D \n",
    "def cohens_d(group1, group2):\n",
    "    # Calculate mean, sd\n",
    "    mean1, mean2 = np.mean(group1), np.mean(group2)\n",
    "    std1, std2 = np.std(group1, ddof=1), np.std(group2, ddof=1)\n",
    "    \n",
    "    # sample size\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    \n",
    "    # Calculate pooled sd\n",
    "    pooled_std = np.sqrt(((n1 - 1) * std1**2 + (n2 - 1) * std2**2) / (n1 + n2 - 2))\n",
    "    \n",
    "    # Cohen's d\n",
    "    d = (mean1 - mean2) / pooled_std\n",
    "    return d\n",
    "\n",
    "# Calculate Effect Size\n",
    "effect_size = cohens_d(before_mean, after_mean)\n",
    "print(\"effect size \\n\", effect_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_i = wb[\"independent t\"]\n",
    "ws_i.cell(row=row, column=1).value = f\"{name}\"\n",
    "ws_i.cell(row=row, column=2).value = mean_before\n",
    "ws_i.cell(row=row, column=3).value = mean_after\n",
    "ws_i.cell(row=row, column=4).value = t_stat\n",
    "ws_i.cell(row=row, column=5).value = p_value_str\n",
    "ws_i.cell(row=row, column=7).value = effect_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paired t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정금례, paired t test\n",
      "mean_before :\n",
      "  5.493433388143091e-09\n",
      "mean_after : \n",
      " 1.1066684670646506e-08\n",
      "KS Statistic: \n",
      " 0.4999999804785107\n",
      "KS p-value: \n",
      " 0.0\n",
      "t_statistics : \n",
      " -269.6740062537641\n",
      "p-value: \n",
      " 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
      "effect size \n",
      " -0.44814076002292047\n"
     ]
    }
   ],
   "source": [
    "# Before vs After segmentation\n",
    "tfr_before = tfr.copy().crop(tmin=0, tmax=3600, include_tmax=False)\n",
    "tfr_after = tfr.copy().crop(tmin=3600, tmax=7199, include_tmax=False)\n",
    "\n",
    "# Averaging\n",
    "before_mean = tfr_mean(tfr_before)\n",
    "after_mean = tfr_mean(tfr_after)\n",
    "\n",
    "# trim the data 무조건 7200초 맞춰서 이 부분 안 써도 되도록 해야함. \n",
    "if len(before_mean) > len(after_mean):\n",
    "    before_mean = before_mean[:len(after_mean)]\n",
    "elif len(before_mean) < len(after_mean):\n",
    "    after_mean = after_mean[:len(before_mean)]\n",
    "else:\n",
    "    quit\n",
    "\n",
    "len(before_mean) == len(after_mean)\n",
    "\n",
    "# Indexing about large artifact\n",
    "\n",
    "before_idx = set()\n",
    "after_idx = set()\n",
    "\n",
    "for t_start, t_end in large_artifact:\n",
    "    if t_start < 3600 and t_end < 3600:\n",
    "        before_idx.update(range(t_start*200, t_end*200))\n",
    "        after_idx.update(range(t_start*200, t_end*200))\n",
    "    elif t_start < 3600 and t_end >= 3600:\n",
    "        before_idx.update(range(t_start*200, 3600*200))\n",
    "        after_idx.update(range(t_start*200, 3600*200))\n",
    "        after_idx.update(range(0, (t_end-3600)*200))\n",
    "        before_idx.update(range(0, (t_end-3600)*200))\n",
    "    else:\n",
    "        after_idx.update(range((t_start-3600)*200, (t_end-3600)*200))\n",
    "        before_idx.update(range((t_start-3600)*200, (t_end-3600)*200))\n",
    "\n",
    "# Convert sets back to sorted lists\n",
    "before_idx = sorted(before_idx)\n",
    "after_idx = sorted(after_idx)\n",
    "\n",
    "before_mean_clean = np.delete(before_mean, before_idx)\n",
    "after_mean_clean = np.delete(after_mean, after_idx)\n",
    "\n",
    "# Paired t-test\n",
    "# precision\n",
    "getcontext().prec = 50\n",
    "\n",
    "print(f\"{name}, paired t test\")\n",
    "# mean of before vs after\n",
    "mean_before = np.mean(before_mean_clean)\n",
    "mean_after = np.mean(after_mean_clean)\n",
    "print(\"mean_before :\\n \", mean_before)\n",
    "print(\"mean_after : \\n\", mean_after)\n",
    "\n",
    "# Kolmogorov-Smirnov test\n",
    "difference = before_mean_clean-after_mean_clean\n",
    "ks_statistic, ks_p_value = stats.kstest(difference, stats.norm.cdf)\n",
    "print(f\"KS Statistic: \\n {ks_statistic}\")\n",
    "print(f\"KS p-value: \\n {ks_p_value}\")\n",
    "\n",
    "# t-test\n",
    "t_stat, p_value = stats.ttest_rel(before_mean, after_mean)\n",
    "\n",
    "# print to decimal object\n",
    "p_value_decimal = Decimal(p_value)\n",
    "print (\"t_statistics : \\n\", t_stat)\n",
    "p_value_str = f\"{p_value_decimal:.100f}\"\n",
    "print(f\"p-value: \\n {p_value_str}\")\n",
    "\n",
    "# Define Cohens'D \n",
    "def cohens_d(group1, group2):\n",
    "    # Calculate mean, sd\n",
    "    mean1, mean2 = np.mean(group1), np.mean(group2)\n",
    "    std1, std2 = np.std(group1, ddof=1), np.std(group2, ddof=1)\n",
    "    \n",
    "    # sample size\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    \n",
    "    # Calculate pooled sd\n",
    "    pooled_std = np.sqrt(((n1 - 1) * std1**2 + (n2 - 1) * std2**2) / (n1 + n2 - 2))\n",
    "    \n",
    "    # Cohen's d\n",
    "    d = (mean1 - mean2) / pooled_std\n",
    "    return d\n",
    "\n",
    "# Calculate Effect Size\n",
    "effect_size = cohens_d(before_mean, after_mean)\n",
    "print(\"effect size \\n\", effect_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_p = wb[\"paired t\"]\n",
    "ws_p.cell(row=row, column=1).value = f\"{name}\"\n",
    "ws_p.cell(row=row, column=2).value = mean_before\n",
    "ws_p.cell(row=row, column=3).value = mean_after\n",
    "ws_p.cell(row=row, column=4).value = ks_statistic\n",
    "ws_p.cell(row=row, column=5).value = ks_p_value\n",
    "ws_p.cell(row=row, column=7).value = t_stat\n",
    "ws_p.cell(row=row, column=8).value = p_value_str\n",
    "ws_p.cell(row=row, column=10).value = effect_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis across Band"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paired t-test with Cohen's D test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta 대역 처리 완료: before 길이 = 719800, after 길이 = 719800\n",
      "Theta 대역 처리 완료: before 길이 = 719800, after 길이 = 719800\n",
      "Alpha 대역 처리 완료: before 길이 = 719800, after 길이 = 719800\n",
      "Beta 대역 처리 완료: before 길이 = 719800, after 길이 = 719800\n",
      "Delta 대역 처리 완료:\n",
      "  Before: 원본 길이 = 719800, 정제 후 길이 = 702000\n",
      "  After: 원본 길이 = 719800, 정제 후 길이 = 702000\n",
      "  정제 후 Before와 After 길이 일치: True\n",
      "Theta 대역 처리 완료:\n",
      "  Before: 원본 길이 = 719800, 정제 후 길이 = 702000\n",
      "  After: 원본 길이 = 719800, 정제 후 길이 = 702000\n",
      "  정제 후 Before와 After 길이 일치: True\n",
      "Alpha 대역 처리 완료:\n",
      "  Before: 원본 길이 = 719800, 정제 후 길이 = 702000\n",
      "  After: 원본 길이 = 719800, 정제 후 길이 = 702000\n",
      "  정제 후 Before와 After 길이 일치: True\n",
      "Beta 대역 처리 완료:\n",
      "  Before: 원본 길이 = 719800, 정제 후 길이 = 702000\n",
      "  After: 원본 길이 = 719800, 정제 후 길이 = 702000\n",
      "  정제 후 Before와 After 길이 일치: True\n",
      "\n",
      " 정금례, paired t test by band\n",
      "\n",
      "=== Delta 대역 분석 결과 ===\n",
      "mean_before: \n",
      " 2.958972620173668e-08\n",
      "mean_after: \n",
      " 6.530964989583494e-08\n",
      "KS Statistic: \n",
      " 0.4999999213825592\n",
      "KS p-value: \n",
      " 0.0\n",
      "t_statistics: \n",
      " -491.89316835297774\n",
      "p-value: \n",
      " 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
      "Effect size: \n",
      " -0.8509339451035465\n",
      "\n",
      "=== Theta 대역 분석 결과 ===\n",
      "mean_before: \n",
      " 7.969693614375677e-09\n",
      "mean_after: \n",
      " 1.1746665645436728e-08\n",
      "KS Statistic: \n",
      " 0.49999997032690524\n",
      "KS p-value: \n",
      " 0.0\n",
      "t_statistics: \n",
      " -174.83845351669117\n",
      "p-value: \n",
      " 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
      "Effect size: \n",
      " -0.2958492442743946\n",
      "\n",
      "=== Alpha 대역 분석 결과 ===\n",
      "mean_before: \n",
      " 2.510460299728676e-09\n",
      "mean_after: \n",
      " 3.92049983302778e-09\n",
      "KS Statistic: \n",
      " 0.49999998276152047\n",
      "KS p-value: \n",
      " 0.0\n",
      "t_statistics: \n",
      " -150.7301835240492\n",
      "p-value: \n",
      " 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
      "Effect size: \n",
      " -0.25482247908414646\n",
      "\n",
      "=== Beta 대역 분석 결과 ===\n",
      "mean_before: \n",
      " 6.590773480617939e-10\n",
      "mean_after: \n",
      " 1.043838656335842e-09\n",
      "KS Statistic: \n",
      " 0.49999999086614433\n",
      "KS p-value: \n",
      " 0.0\n",
      "t_statistics: \n",
      " -113.17012199164117\n",
      "p-value: \n",
      " 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
      "Effect size: \n",
      " -0.19090454105405727\n"
     ]
    }
   ],
   "source": [
    "freq_ranges = {\n",
    "    'Delta': (1, 4),\n",
    "    'Theta': (4, 8),\n",
    "    'Alpha': (8, 13),\n",
    "    'Beta': (13, 30),\n",
    "}\n",
    "\n",
    "# Averaging by band and timing\n",
    "for band, (fmin, fmax) in freq_ranges.items():\n",
    "    tfr_band_before = tfr.copy().crop(tmin=0, tmax=3600, fmin=fmin, fmax=fmax, include_tmax=False)\n",
    "    tfr_band_after = tfr.copy().crop(tmin=3600, tmax=7199, fmin=fmin, fmax=fmax, include_tmax=False)\n",
    "\n",
    "    globals()[f'tfr_{band}_before'] = tfr_band_before\n",
    "    globals()[f'tfr_{band}_after'] = tfr_band_after\n",
    "\n",
    "    globals()[f'{band}_before_mean'] = tfr_mean(tfr_band_before)\n",
    "    globals()[f'{band}_after_mean'] = tfr_mean(tfr_band_after)\n",
    "\n",
    "# Make length same    \n",
    "for band in freq_ranges.keys():\n",
    "    before_mean = globals()[f'{band}_before_mean']\n",
    "    after_mean = globals()[f'{band}_after_mean']\n",
    "\n",
    "    if len(before_mean) > len(after_mean):\n",
    "        globals()[f'{band}_before_mean'] = before_mean[:len(after_mean)]\n",
    "    elif len(before_mean) < len(after_mean):\n",
    "        globals()[f'{band}_after_mean'] = after_mean[:len(before_mean)]\n",
    "    else:\n",
    "        print(f\"{band} 대역의 before와 after 길이가 이미 같습니다.\")\n",
    "\n",
    "    print(f\"{band} 대역 처리 완료: before 길이 = {len(globals()[f'{band}_before_mean'])}, after 길이 = {len(globals()[f'{band}_after_mean'])}\")\n",
    "\n",
    "# Removing large artifact by band\n",
    "def remove_artifacts(before_mean, after_mean, large_artifact):\n",
    "    before_idx = set()\n",
    "    after_idx = set()\n",
    "\n",
    "    for t_start, t_end in large_artifact:\n",
    "        if t_start < 3600 and t_end < 3600:\n",
    "            before_idx.update(range(t_start*200, t_end*200))\n",
    "            after_idx.update(range(t_start*200, t_end*200))\n",
    "        elif t_start < 3600 and t_end >= 3600:\n",
    "            before_idx.update(range(t_start*200, 3600*200))\n",
    "            after_idx.update(range(t_start*200, 3600*200))\n",
    "            after_idx.update(range(0, (t_end-3600)*200))\n",
    "            before_idx.update(range(0, (t_end-3600)*200))\n",
    "        else:\n",
    "            after_idx.update(range((t_start-3600)*200, (t_end-3600)*200))\n",
    "            before_idx.update(range((t_start-3600)*200, (t_end-3600)*200))\n",
    "\n",
    "    before_idx = sorted(before_idx)\n",
    "    after_idx = sorted(after_idx)\n",
    "\n",
    "    before_mean_clean = np.delete(before_mean, before_idx)\n",
    "    after_mean_clean = np.delete(after_mean, after_idx)\n",
    "\n",
    "    return before_mean_clean, after_mean_clean\n",
    "\n",
    "# 주파수 대역별로 artifact 제거\n",
    "for band in freq_ranges.keys():\n",
    "    before_mean = globals()[f'{band}_before_mean']\n",
    "    after_mean = globals()[f'{band}_after_mean']\n",
    "\n",
    "    before_mean_clean, after_mean_clean = remove_artifacts(before_mean, after_mean, large_artifact)\n",
    "\n",
    "    globals()[f'{band}_before_mean_clean'] = before_mean_clean\n",
    "    globals()[f'{band}_after_mean_clean'] = after_mean_clean\n",
    "\n",
    "    print(f\"{band} 대역 처리 완료:\")\n",
    "    print(f\"  Before: 원본 길이 = {len(before_mean)}, 정제 후 길이 = {len(before_mean_clean)}\")\n",
    "    print(f\"  After: 원본 길이 = {len(after_mean)}, 정제 후 길이 = {len(after_mean_clean)}\")\n",
    "    print(f\"  정제 후 Before와 After 길이 일치: {len(before_mean_clean) == len(after_mean_clean)}\")\n",
    "\n",
    "print(f\"\\n {name}, paired t test by band\")\n",
    "def run_tests(before_mean, after_mean, band_name):\n",
    "    print(f\"\\n=== {band_name} 대역 분석 결과 ===\")\n",
    "    \n",
    "    # precision\n",
    "    getcontext().prec = 50\n",
    "\n",
    "    # mean of before vs after\n",
    "    mean_before = np.mean(before_mean)\n",
    "    mean_after = np.mean(after_mean)\n",
    "    print(f\"mean_before: \\n {mean_before}\")\n",
    "    print(f\"mean_after: \\n {mean_after}\")\n",
    "\n",
    "    # Kolmogorov-Smirnov test\n",
    "    difference = before_mean - after_mean\n",
    "    ks_statistic, ks_p_value = stats.kstest(difference, stats.norm.cdf)\n",
    "    print(f\"KS Statistic: \\n {ks_statistic}\")\n",
    "    print(f\"KS p-value: \\n {ks_p_value}\")\n",
    "\n",
    "    # t-test\n",
    "    t_stat, p_value = stats.ttest_rel(before_mean, after_mean)\n",
    "\n",
    "    # print to decimal object\n",
    "    p_value_decimal = Decimal(p_value)\n",
    "    print(f\"t_statistics: \\n {t_stat}\")\n",
    "    p_value_str = f\"{p_value_decimal:.100f}\"\n",
    "    print(f\"p-value: \\n {p_value_str}\")\n",
    "\n",
    "    # Define Cohens'D \n",
    "    def cohens_d(group1, group2):\n",
    "        mean1, mean2 = np.mean(group1), np.mean(group2)\n",
    "        std1, std2 = np.std(group1, ddof=1), np.std(group2, ddof=1)\n",
    "        n1, n2 = len(group1), len(group2)\n",
    "        pooled_std = np.sqrt(((n1 - 1) * std1**2 + (n2 - 1) * std2**2) / (n1 + n2 - 2))\n",
    "        d = (mean1 - mean2) / pooled_std\n",
    "        return d\n",
    "\n",
    "    # Calculate Effect Size\n",
    "    effect_size = cohens_d(before_mean, after_mean)\n",
    "    print(f\"Effect size: \\n {effect_size}\")\n",
    "\n",
    "# 각 주파수 대역별로 테스트 실행\n",
    "for band in freq_ranges.keys():\n",
    "    before_mean = globals()[f'{band}_before_mean_clean']\n",
    "    after_mean = globals()[f'{band}_after_mean_clean']\n",
    "    run_tests(before_mean, after_mean, band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_b = wb[\"paired t band\"]\n",
    "for row_b in [row*4-6, row*4-5, row*4-4, row*4-3]:\n",
    "    ws_b.cell(row=row_b, column=1).value = f\"{name}\"\n",
    "    ws_b.cell(row=row_b, column=4).value = mean_before\n",
    "    ws_b.cell(row=row_b, column=5).value = mean_after\n",
    "    ws_b.cell(row=row_b, column=6).value = ks_statistic\n",
    "    ws_b.cell(row=row_b, column=7).value = ks_p_value\n",
    "    ws_b.cell(row=row_b, column=9).value = t_stat\n",
    "    ws_b.cell(row=row_b, column=10).value = p_value_str\n",
    "    ws_b.cell(row=row_b, column=12).value = effect_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.save(r\"C:\\Users\\esin4\\OneDrive\\바탕 화면\\Github\\Mg_infusion_coma\\Mg_infusion_data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RM ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for band in freq_ranges.keys():\n",
    "    before_mean = globals()[f'{band}_before_mean_clean']\n",
    "    after_mean = globals()[f'{band}_after_mean_clean']\n",
    "    \n",
    "    before_mean_mean = np.mean(before_mean)\n",
    "    after_mean_mean = np.mean(after_mean)\n",
    "    \n",
    "    globals()[f'{band.lower()}_before_mean_mean'] = before_mean_mean\n",
    "    globals()[f'{band.lower()}_after_mean_mean'] = after_mean_mean\n",
    "    \n",
    "    print(f\"\\n=== {band} 대역 평균 ===\")\n",
    "    print(f\"{band} Before Mean of Mean: {before_mean_mean}\")\n",
    "    print(f\"{band} After Mean of Mean: {after_mean_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'Band': ['Delta', 'Delta', 'Theta', 'Theta', 'Alpha', 'Alpha', 'Beta', 'Beta'],\n",
    "    'Time': ['Before', 'After', 'Before', 'After', 'Before', 'After', 'Before', 'After'],\n",
    "    'Power': [delta_before_mean_mean, delta_after_mean_mean, theta_before_mean_mean, theta_after_mean_mean, \n",
    "              alpha_before_mean_mean, alpha_after_mean_mean, beta_before_mean_mean, beta_after_mean_mean]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "\n",
    "# 반복측정 ANOVA 모델 설정\n",
    "aovrm = AnovaRM(data, 'Power', 'Band', within=['Time'])\n",
    "res = aovrm.fit()\n",
    "\n",
    "# 결과 출력\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
