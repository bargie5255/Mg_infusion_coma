{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before Analysis..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFR을 선택하였습니다.\n",
      "Opening raw data file H:\\Mg_EEG\\edf_files\\정광훈2_7200_clean.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esin4\\AppData\\Local\\Temp\\ipykernel_14144\\536985483.py:19: RuntimeWarning: This filename (H:\\Mg_EEG\\edf_files\\정광훈2_7200_clean.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  clean_data = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 1439800 =      0.000 ...  7199.000 secs\n",
      "Ready.\n",
      "Reading 0 ... 1439800  =      0.000 ...  7199.000 secs...\n",
      "fif 파일을 성공적으로 불러왔습니다: H:\\Mg_EEG\\edf_files\\정광훈2_7200_clean.fif\n",
      "TFR을 계산 중 입니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 1450] 시스템 리소스가 부족하기 때문에 요청한 서비스를 완성할 수 없습니다",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\esin4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 370, in _sendback_result\n    result_queue.put(\n  File \"c:\\Users\\esin4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\queues.py\", line 233, in put\n    self._writer.send_bytes(obj)\n  File \"c:\\Users\\esin4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\connection.py\", line 200, in send_bytes\n    self._send_bytes(m[offset:offset + size])\n  File \"c:\\Users\\esin4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\connection.py\", line 289, in _send_bytes\n    ov, err = _winapi.WriteFile(self._handle, buf, overlapped=True)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nOSError: [WinError 1450] 시스템 리소스가 부족하기 때문에 요청한 서비스를 완성할 수 없습니다\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Computing TFR\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTFR을 계산 중 입니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m tfr \u001b[38;5;241m=\u001b[39m \u001b[43mclean_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_tfr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmultitaper\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m31\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7199\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreject_by_annotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTFR 계산이 완료되었습니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# TFR 파일 저장\u001b[39;00m\n",
      "File \u001b[1;32m<decorator-gen-199>:12\u001b[0m, in \u001b[0;36mcompute_tfr\u001b[1;34m(self, method, freqs, tmin, tmax, picks, proj, output, reject_by_annotation, decim, n_jobs, verbose, **method_kw)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\esin4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mne\\io\\base.py:2297\u001b[0m, in \u001b[0;36mBaseRaw.compute_tfr\u001b[1;34m(self, method, freqs, tmin, tmax, picks, proj, output, reject_by_annotation, decim, n_jobs, verbose, **method_kw)\u001b[0m\n\u001b[0;32m   2295\u001b[0m _check_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m, output, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpower\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphase\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplex\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   2296\u001b[0m method_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m-> 2297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRawTFR\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2298\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpicks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpicks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreject_by_annotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreject_by_annotation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2309\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmethod_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2310\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\esin4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mne\\time_frequency\\tfr.py:3858\u001b[0m, in \u001b[0;36mRawTFR.__init__\u001b[1;34m(self, inst, method, freqs, tmin, tmax, picks, proj, reject_by_annotation, decim, n_jobs, verbose, **method_kw)\u001b[0m\n\u001b[0;32m   3854\u001b[0m \u001b[38;5;66;03m# dict is allowed for __setstate__ compatibility\u001b[39;00m\n\u001b[0;32m   3855\u001b[0m _validate_type(\n\u001b[0;32m   3856\u001b[0m     inst, (BaseRaw, \u001b[38;5;28mdict\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject passed to RawTFR constructor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaw\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3857\u001b[0m )\n\u001b[1;32m-> 3858\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3859\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpicks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpicks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3865\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreject_by_annotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreject_by_annotation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3867\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3868\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3869\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3870\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmethod_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3871\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\esin4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mne\\time_frequency\\tfr.py:1274\u001b[0m, in \u001b[0;36mBaseTFR.__init__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decim \u001b[38;5;241m=\u001b[39m _ensure_slice(decim)\n\u001b[0;32m   1273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_times \u001b[38;5;241m=\u001b[39m inst\u001b[38;5;241m.\u001b[39mtimes[time_mask]\n\u001b[1;32m-> 1274\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_tfr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_epoch_attributes()\n\u001b[0;32m   1276\u001b[0m \u001b[38;5;66;03m# \"apply\" decim to the rest of the object (data is decimated in _compute_tfr)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\esin4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mne\\time_frequency\\tfr.py:1535\u001b[0m, in \u001b[0;36mBaseTFR._compute_tfr\u001b[1;34m(self, data, n_jobs, verbose)\u001b[0m\n\u001b[0;32m   1534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_tfr\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, n_jobs, verbose):\n\u001b[1;32m-> 1535\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tfr_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1536\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1537\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1542\u001b[0m     \u001b[38;5;66;03m# assign ._data and maybe ._itc\u001b[39;00m\n\u001b[0;32m   1543\u001b[0m     \u001b[38;5;66;03m# tfr_array_stockwell always returns ITC (sometimes it's None)\u001b[39;00m\n\u001b[0;32m   1544\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstockwell\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m<decorator-gen-147>:12\u001b[0m, in \u001b[0;36mtfr_array_multitaper\u001b[1;34m(data, sfreq, freqs, n_cycles, zero_mean, time_bandwidth, use_fft, decim, output, n_jobs, verbose, epoch_data)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\esin4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mne\\time_frequency\\multitaper.py:556\u001b[0m, in \u001b[0;36mtfr_array_multitaper\u001b[1;34m(data, sfreq, freqs, n_cycles, zero_mean, time_bandwidth, use_fft, decim, output, n_jobs, verbose, epoch_data)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    550\u001b[0m     warn(\n\u001b[0;32m    551\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe parameter for providing data will be switched from `epoch_data` to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    552\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`data` in 1.8. Use the `data` parameter to avoid this warning.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    553\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    554\u001b[0m     )\n\u001b[1;32m--> 556\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compute_tfr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43msfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmultitaper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_cycles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_cycles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mzero_mean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_bandwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_bandwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\esin4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mne\\time_frequency\\tfr.py:577\u001b[0m, in \u001b[0;36m_compute_tfr\u001b[1;34m(epoch_data, freqs, sfreq, method, n_cycles, zero_mean, time_bandwidth, use_fft, decim, output, n_jobs, verbose)\u001b[0m\n\u001b[0;32m    574\u001b[0m parallel, my_cwt, n_jobs \u001b[38;5;241m=\u001b[39m parallel_func(_time_frequency_loop, n_jobs)\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Parallelization is applied across channels.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m tfrs \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmy_cwt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mepoch_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;66;03m# FIXME: to avoid overheads we should use np.array_split()\u001b[39;00m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m channel_idx, tfr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tfrs):\n",
      "File \u001b[1;32mc:\\Users\\esin4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\esin4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\esin4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\esin4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\esin4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\esin4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1450] 시스템 리소스가 부족하기 때문에 요청한 서비스를 완성할 수 없습니다"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from decimal import Decimal, getcontext\n",
    "import pandas as pd\n",
    "import ast\n",
    "import openpyxl as op\n",
    "\n",
    "# 분석대상 이름 입력\n",
    "name = input(\"분석대상 이름을 입력하세요.\")\n",
    "purpose = input(\"목적을 입력하세요. TFR or loading\")\n",
    "\n",
    "if purpose == \"TFR\":\n",
    "    print(f\"TFR을 선택하였습니다.\")\n",
    "    # fif 파일 불러오기\n",
    "    file_path = rf'H:\\Mg_EEG\\edf_files\\{name}_7200_clean.fif'\n",
    "    clean_data = mne.io.read_raw_fif(file_path, preload=True)\n",
    "\n",
    "    print(f\"fif 파일을 성공적으로 불러왔습니다: {file_path}\")\n",
    "    \n",
    "    # Computing TFR\n",
    "    print(f\"TFR을 계산 중 입니다.\")\n",
    "    tfr = clean_data.compute_tfr(method='multitaper', freqs=np.arange(1, 31), tmin=0, tmax=7199, n_jobs=-1, reject_by_annotation=False)\n",
    "    print(f\"TFR 계산이 완료되었습니다.\")\n",
    "\n",
    "    # TFR 파일 저장\n",
    "    saving_path = rf'H:\\Mg_EEG\\tfr_files\\{name}_7200_tfr.h5'\n",
    "    tfr.save(saving_path, overwrite=True)\n",
    "    print(f\"TFR 파일이 성공적으로 저장되었습니다.\")\n",
    "\n",
    "    # Saving raw file for back-up\n",
    "    tfr_raw = tfr.copy()\n",
    "\n",
    "elif purpose == \"loading\":\n",
    "    print(f\"loading을 선택하였습니다.\")\n",
    "    # Loading saved TFR file\n",
    "    file_path = rf'H:\\Mg_EEG\\tfr_files\\{name}_7200_tfr.h5'\n",
    "    tfr = mne.time_frequency.read_tfrs(file_path)\n",
    "    print(f\"성공적으로 tfr 파일을 로딩하였습니다.\")\n",
    "\n",
    "    # Saving raw file for back-up\n",
    "    tfr_raw = tfr.copy()\n",
    "\n",
    "else:\n",
    "    print(\"올바른 값을 입력하시오\")\n",
    "    quit()\n",
    "\n",
    "def tfr_mean(tfr):\n",
    "    mean_electrode = np.mean(tfr.data, axis=0) # Averaging across electrode\n",
    "    mean_frequency = np.mean(mean_electrode, axis=0) # Averaging across frequency\n",
    "    return(mean_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw fif file 보고 싶다면 사용\n",
    "#clean_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터가 뭔가 이상할 때 리셋하는 복구 코드\n",
    "#tfr = tfr_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# large artifact data load\n",
    "csv_file_path = r'C:\\Users\\esin4\\OneDrive\\바탕 화면\\Github\\Mg_infusion_coma\\large_artifact.csv'\n",
    "\n",
    "large_artifact_data = pd.read_csv(csv_file_path, encoding='utf-8-sig')\n",
    "\n",
    "# 입력한 이름이 데이터프레임에 존재하는지 확인하고 좌표 가져오기\n",
    "if name in large_artifact_data['Name'].values:\n",
    "    # 입력한 이름에 해당하는 데이터 가져오기\n",
    "    coordinates = large_artifact_data[large_artifact_data['Name'] == name]['Coordinates'].values[0]\n",
    "    \n",
    "    # 좌표가 'skip'이면 빈 리스트로 설정\n",
    "    if coordinates == 'skip':\n",
    "        large_artifact = []\n",
    "    else:\n",
    "        # 좌표 문자열을 리스트로 변환\n",
    "        import ast\n",
    "        large_artifact = ast.literal_eval(coordinates)\n",
    "else:\n",
    "    print(f\"{input_name}이(가) 데이터에 없습니다.\")\n",
    "    large_artifact = []\n",
    "\n",
    "# 결과 출력\n",
    "print(\"large_artifact 리스트:\")\n",
    "print(large_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석한 값 저장할 엑셀 파일\n",
    "wb = op.load_workbook(r\"C:\\Users\\esin4\\OneDrive\\바탕 화면\\Github\\Mg_infusion_coma\\Mg_infusion_data.xlsx\")\n",
    "row = int(input(\"데이터가 입력될 행을 입력하세요.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# independent t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before vs After segmentation\n",
    "tfr_before = tfr.copy().crop(tmin=0, tmax=3600, include_tmax=False)\n",
    "tfr_after = tfr.copy().crop(tmin=3600, tmax=7199, include_tmax=False)\n",
    "\n",
    "# Averaging\n",
    "before_mean = tfr_mean(tfr_before)\n",
    "after_mean = tfr_mean(tfr_after)\n",
    "\n",
    "# Indexing about Large artifact\n",
    "before_idx = []\n",
    "after_idx = []\n",
    "\n",
    "for t_start, t_end in large_artifact:\n",
    "    if t_start < 3600 and t_end < 3600:\n",
    "        before_idx.extend(range(t_start*200, t_end*200))\n",
    "    elif t_start < 3600 and t_end >= 3600:\n",
    "        before_idx.extend(range(t_start*200, 3600*200))\n",
    "        after_idx.extend(range(0, (t_end-3600)*200))\n",
    "    else:\n",
    "        after_idx.extend(range((t_start-3600)*200, (t_end-3600)*200))\n",
    "\n",
    "# Removing Large artifacts\n",
    "before_mean_clean = np.delete(before_mean, before_idx)\n",
    "after_mean_clean = np.delete(after_mean, after_idx)\n",
    "\n",
    "# independent t-test\n",
    "# precision\n",
    "getcontext().prec = 50\n",
    "\n",
    "print(f\"{name}, independent t test\")\n",
    "# mean of before vs after\n",
    "mean_before = np.mean(before_mean_clean)\n",
    "mean_after = np.mean(after_mean_clean)\n",
    "print(\"mean_before : \\n\", mean_before)\n",
    "print(\"mean_after : \\n\", mean_after)\n",
    "\n",
    "# t-test\n",
    "t_stat, p_value = stats.ttest_ind(before_mean_clean, after_mean_clean)\n",
    "\n",
    "# print to decimal object\n",
    "p_value_decimal = Decimal(p_value)\n",
    "print (\"t_statistics : \\n\", t_stat)\n",
    "p_value_str = f\"{p_value_decimal:.100f}\"\n",
    "print(f\"p-value: \\n {p_value_str}\")\n",
    "\n",
    "# Define Cohens'D \n",
    "def cohens_d(group1, group2):\n",
    "    # Calculate mean, sd\n",
    "    mean1, mean2 = np.mean(group1), np.mean(group2)\n",
    "    std1, std2 = np.std(group1, ddof=1), np.std(group2, ddof=1)\n",
    "    \n",
    "    # sample size\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    \n",
    "    # Calculate pooled sd\n",
    "    pooled_std = np.sqrt(((n1 - 1) * std1**2 + (n2 - 1) * std2**2) / (n1 + n2 - 2))\n",
    "    \n",
    "    # Cohen's d\n",
    "    d = (mean1 - mean2) / pooled_std\n",
    "    return d\n",
    "\n",
    "# Calculate Effect Size\n",
    "effect_size = cohens_d(before_mean, after_mean)\n",
    "print(\"effect size \\n\", effect_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_i = wb[\"independent t\"]\n",
    "ws_i.cell(row=row, column=1).value = f\"{name}\"\n",
    "ws_i.cell(row=row, column=2).value = mean_before\n",
    "ws_i.cell(row=row, column=3).value = mean_after\n",
    "ws_i.cell(row=row, column=4).value = t_stat\n",
    "ws_i.cell(row=row, column=5).value = p_value_str\n",
    "ws_i.cell(row=row, column=7).value = effect_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paired t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before vs After segmentation\n",
    "tfr_before = tfr.copy().crop(tmin=0, tmax=3600, include_tmax=False)\n",
    "tfr_after = tfr.copy().crop(tmin=3600, tmax=7199, include_tmax=False)\n",
    "\n",
    "# Averaging\n",
    "before_mean = tfr_mean(tfr_before)\n",
    "after_mean = tfr_mean(tfr_after)\n",
    "\n",
    "# trim the data 무조건 7200초 맞춰서 이 부분 안 써도 되도록 해야함. \n",
    "if len(before_mean) > len(after_mean):\n",
    "    before_mean = before_mean[:len(after_mean)]\n",
    "elif len(before_mean) < len(after_mean):\n",
    "    after_mean = after_mean[:len(before_mean)]\n",
    "else:\n",
    "    quit\n",
    "\n",
    "len(before_mean) == len(after_mean)\n",
    "\n",
    "# Indexing about large artifact\n",
    "\n",
    "before_idx = set()\n",
    "after_idx = set()\n",
    "\n",
    "for t_start, t_end in large_artifact:\n",
    "    if t_start < 3600 and t_end < 3600:\n",
    "        before_idx.update(range(t_start*200, t_end*200))\n",
    "        after_idx.update(range(t_start*200, t_end*200))\n",
    "    elif t_start < 3600 and t_end >= 3600:\n",
    "        before_idx.update(range(t_start*200, 3600*200))\n",
    "        after_idx.update(range(t_start*200, 3600*200))\n",
    "        after_idx.update(range(0, (t_end-3600)*200))\n",
    "        before_idx.update(range(0, (t_end-3600)*200))\n",
    "    else:\n",
    "        after_idx.update(range((t_start-3600)*200, (t_end-3600)*200))\n",
    "        before_idx.update(range((t_start-3600)*200, (t_end-3600)*200))\n",
    "\n",
    "# Convert sets back to sorted lists\n",
    "before_idx = sorted(before_idx)\n",
    "after_idx = sorted(after_idx)\n",
    "\n",
    "before_mean_clean = np.delete(before_mean, before_idx)\n",
    "after_mean_clean = np.delete(after_mean, after_idx)\n",
    "\n",
    "# Paired t-test\n",
    "# precision\n",
    "getcontext().prec = 50\n",
    "\n",
    "print(f\"{name}, paired t test\")\n",
    "# mean of before vs after\n",
    "mean_before = np.mean(before_mean_clean)\n",
    "mean_after = np.mean(after_mean_clean)\n",
    "print(\"mean_before :\\n \", mean_before)\n",
    "print(\"mean_after : \\n\", mean_after)\n",
    "\n",
    "# Kolmogorov-Smirnov test\n",
    "difference = before_mean_clean-after_mean_clean\n",
    "ks_statistic, ks_p_value = stats.kstest(difference, stats.norm.cdf)\n",
    "print(f\"KS Statistic: \\n {ks_statistic}\")\n",
    "print(f\"KS p-value: \\n {ks_p_value}\")\n",
    "\n",
    "# t-test\n",
    "t_stat, p_value = stats.ttest_rel(before_mean, after_mean)\n",
    "\n",
    "# print to decimal object\n",
    "p_value_decimal = Decimal(p_value)\n",
    "print (\"t_statistics : \\n\", t_stat)\n",
    "p_value_str = f\"{p_value_decimal:.100f}\"\n",
    "print(f\"p-value: \\n {p_value_str}\")\n",
    "\n",
    "# Define Cohens'D \n",
    "def cohens_d(group1, group2):\n",
    "    # Calculate mean, sd\n",
    "    mean1, mean2 = np.mean(group1), np.mean(group2)\n",
    "    std1, std2 = np.std(group1, ddof=1), np.std(group2, ddof=1)\n",
    "    \n",
    "    # sample size\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    \n",
    "    # Calculate pooled sd\n",
    "    pooled_std = np.sqrt(((n1 - 1) * std1**2 + (n2 - 1) * std2**2) / (n1 + n2 - 2))\n",
    "    \n",
    "    # Cohen's d\n",
    "    d = (mean1 - mean2) / pooled_std\n",
    "    return d\n",
    "\n",
    "# Calculate Effect Size\n",
    "effect_size = cohens_d(before_mean, after_mean)\n",
    "print(\"effect size \\n\", effect_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_p = wb[\"paired t\"]\n",
    "ws_p.cell(row=row, column=1).value = f\"{name}\"\n",
    "ws_p.cell(row=row, column=2).value = mean_before\n",
    "ws_p.cell(row=row, column=3).value = mean_after\n",
    "ws_p.cell(row=row, column=4).value = ks_statistic\n",
    "ws_p.cell(row=row, column=5).value = ks_p_value\n",
    "ws_p.cell(row=row, column=7).value = t_stat\n",
    "ws_p.cell(row=row, column=8).value = p_value_str\n",
    "ws_p.cell(row=row, column=10).value = effect_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis across Band"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paired t-test with Cohen's D test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_ranges = {\n",
    "    'Delta': (1, 4),\n",
    "    'Theta': (4, 8),\n",
    "    'Alpha': (8, 13),\n",
    "    'Beta': (13, 30),\n",
    "}\n",
    "\n",
    "# Averaging by band and timing\n",
    "for band, (fmin, fmax) in freq_ranges.items():\n",
    "    tfr_band_before = tfr.copy().crop(tmin=0, tmax=3600, fmin=fmin, fmax=fmax, include_tmax=False)\n",
    "    tfr_band_after = tfr.copy().crop(tmin=3600, tmax=7199, fmin=fmin, fmax=fmax, include_tmax=False)\n",
    "\n",
    "    globals()[f'tfr_{band}_before'] = tfr_band_before\n",
    "    globals()[f'tfr_{band}_after'] = tfr_band_after\n",
    "\n",
    "    globals()[f'{band}_before_mean'] = tfr_mean(tfr_band_before)\n",
    "    globals()[f'{band}_after_mean'] = tfr_mean(tfr_band_after)\n",
    "\n",
    "# Make length same    \n",
    "for band in freq_ranges.keys():\n",
    "    before_mean = globals()[f'{band}_before_mean']\n",
    "    after_mean = globals()[f'{band}_after_mean']\n",
    "\n",
    "    if len(before_mean) > len(after_mean):\n",
    "        globals()[f'{band}_before_mean'] = before_mean[:len(after_mean)]\n",
    "    elif len(before_mean) < len(after_mean):\n",
    "        globals()[f'{band}_after_mean'] = after_mean[:len(before_mean)]\n",
    "    else:\n",
    "        print(f\"{band} 대역의 before와 after 길이가 이미 같습니다.\")\n",
    "\n",
    "    print(f\"{band} 대역 처리 완료: before 길이 = {len(globals()[f'{band}_before_mean'])}, after 길이 = {len(globals()[f'{band}_after_mean'])}\")\n",
    "\n",
    "# Removing large artifact by band\n",
    "def remove_artifacts(before_mean, after_mean, large_artifact):\n",
    "    before_idx = set()\n",
    "    after_idx = set()\n",
    "\n",
    "    for t_start, t_end in large_artifact:\n",
    "        if t_start < 3600 and t_end < 3600:\n",
    "            before_idx.update(range(t_start*200, t_end*200))\n",
    "            after_idx.update(range(t_start*200, t_end*200))\n",
    "        elif t_start < 3600 and t_end >= 3600:\n",
    "            before_idx.update(range(t_start*200, 3600*200))\n",
    "            after_idx.update(range(t_start*200, 3600*200))\n",
    "            after_idx.update(range(0, (t_end-3600)*200))\n",
    "            before_idx.update(range(0, (t_end-3600)*200))\n",
    "        else:\n",
    "            after_idx.update(range((t_start-3600)*200, (t_end-3600)*200))\n",
    "            before_idx.update(range((t_start-3600)*200, (t_end-3600)*200))\n",
    "\n",
    "    before_idx = sorted(before_idx)\n",
    "    after_idx = sorted(after_idx)\n",
    "\n",
    "    before_mean_clean = np.delete(before_mean, before_idx)\n",
    "    after_mean_clean = np.delete(after_mean, after_idx)\n",
    "\n",
    "    return before_mean_clean, after_mean_clean\n",
    "\n",
    "# 주파수 대역별로 artifact 제거\n",
    "for band in freq_ranges.keys():\n",
    "    before_mean = globals()[f'{band}_before_mean']\n",
    "    after_mean = globals()[f'{band}_after_mean']\n",
    "\n",
    "    before_mean_clean, after_mean_clean = remove_artifacts(before_mean, after_mean, large_artifact)\n",
    "\n",
    "    globals()[f'{band}_before_mean_clean'] = before_mean_clean\n",
    "    globals()[f'{band}_after_mean_clean'] = after_mean_clean\n",
    "\n",
    "    print(f\"{band} 대역 처리 완료:\")\n",
    "    print(f\"  Before: 원본 길이 = {len(before_mean)}, 정제 후 길이 = {len(before_mean_clean)}\")\n",
    "    print(f\"  After: 원본 길이 = {len(after_mean)}, 정제 후 길이 = {len(after_mean_clean)}\")\n",
    "    print(f\"  정제 후 Before와 After 길이 일치: {len(before_mean_clean) == len(after_mean_clean)}\")\n",
    "\n",
    "print(f\"\\n {name}, paired t test by band\")\n",
    "def run_tests(before_mean, after_mean, band_name):\n",
    "    print(f\"\\n=== {band_name} 대역 분석 결과 ===\")\n",
    "    \n",
    "    # precision\n",
    "    getcontext().prec = 50\n",
    "\n",
    "    # mean of before vs after\n",
    "    mean_before = np.mean(before_mean)\n",
    "    mean_after = np.mean(after_mean)\n",
    "    print(f\"mean_before: \\n {mean_before}\")\n",
    "    print(f\"mean_after: \\n {mean_after}\")\n",
    "\n",
    "    # Kolmogorov-Smirnov test\n",
    "    difference = before_mean - after_mean\n",
    "    ks_statistic, ks_p_value = stats.kstest(difference, stats.norm.cdf)\n",
    "    print(f\"KS Statistic: \\n {ks_statistic}\")\n",
    "    print(f\"KS p-value: \\n {ks_p_value}\")\n",
    "\n",
    "    # t-test\n",
    "    t_stat, p_value = stats.ttest_rel(before_mean, after_mean)\n",
    "\n",
    "    # print to decimal object\n",
    "    p_value_decimal = Decimal(p_value)\n",
    "    print(f\"t_statistics: \\n {t_stat}\")\n",
    "    p_value_str = f\"{p_value_decimal:.100f}\"\n",
    "    print(f\"p-value: \\n {p_value_str}\")\n",
    "\n",
    "    # Define Cohens'D \n",
    "    def cohens_d(group1, group2):\n",
    "        mean1, mean2 = np.mean(group1), np.mean(group2)\n",
    "        std1, std2 = np.std(group1, ddof=1), np.std(group2, ddof=1)\n",
    "        n1, n2 = len(group1), len(group2)\n",
    "        pooled_std = np.sqrt(((n1 - 1) * std1**2 + (n2 - 1) * std2**2) / (n1 + n2 - 2))\n",
    "        d = (mean1 - mean2) / pooled_std\n",
    "        return d\n",
    "\n",
    "    # Calculate Effect Size\n",
    "    effect_size = cohens_d(before_mean, after_mean)\n",
    "    print(f\"Effect size: \\n {effect_size}\")\n",
    "\n",
    "# 각 주파수 대역별로 테스트 실행\n",
    "for band in freq_ranges.keys():\n",
    "    before_mean = globals()[f'{band}_before_mean_clean']\n",
    "    after_mean = globals()[f'{band}_after_mean_clean']\n",
    "    run_tests(before_mean, after_mean, band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_b = wb[\"paired t band\"]\n",
    "for row_b in [row*4-6, row*4-5, row*4-4, row*4-3]:\n",
    "    ws_b.cell(row=row_b, column=1).value = f\"{name}\"\n",
    "    ws_b.cell(row=row_b, column=4).value = mean_before\n",
    "    ws_b.cell(row=row_b, column=5).value = mean_after\n",
    "    ws_b.cell(row=row_b, column=6).value = ks_statistic\n",
    "    ws_b.cell(row=row_b, column=7).value = ks_p_value\n",
    "    ws_b.cell(row=row_b, column=9).value = t_stat\n",
    "    ws_b.cell(row=row_b, column=10).value = p_value_str\n",
    "    ws_b.cell(row=row_b, column=12).value = effect_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.save(r\"C:\\Users\\esin4\\OneDrive\\바탕 화면\\Github\\Mg_infusion_coma\\Mg_infusion_data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RM ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for band in freq_ranges.keys():\n",
    "    before_mean = globals()[f'{band}_before_mean_clean']\n",
    "    after_mean = globals()[f'{band}_after_mean_clean']\n",
    "    \n",
    "    before_mean_mean = np.mean(before_mean)\n",
    "    after_mean_mean = np.mean(after_mean)\n",
    "    \n",
    "    globals()[f'{band.lower()}_before_mean_mean'] = before_mean_mean\n",
    "    globals()[f'{band.lower()}_after_mean_mean'] = after_mean_mean\n",
    "    \n",
    "    print(f\"\\n=== {band} 대역 평균 ===\")\n",
    "    print(f\"{band} Before Mean of Mean: {before_mean_mean}\")\n",
    "    print(f\"{band} After Mean of Mean: {after_mean_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'Band': ['Delta', 'Delta', 'Theta', 'Theta', 'Alpha', 'Alpha', 'Beta', 'Beta'],\n",
    "    'Time': ['Before', 'After', 'Before', 'After', 'Before', 'After', 'Before', 'After'],\n",
    "    'Power': [delta_before_mean_mean, delta_after_mean_mean, theta_before_mean_mean, theta_after_mean_mean, \n",
    "              alpha_before_mean_mean, alpha_after_mean_mean, beta_before_mean_mean, beta_after_mean_mean]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "\n",
    "# 반복측정 ANOVA 모델 설정\n",
    "aovrm = AnovaRM(data, 'Power', 'Band', within=['Time'])\n",
    "res = aovrm.fit()\n",
    "\n",
    "# 결과 출력\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
