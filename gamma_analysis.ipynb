{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "고정실,김가람,김득실,김영현,김충연,민병춘1,박주연1,박주연2,벌,안중훈,윤병시,이미우,임석봉,전창희,정광훈2,정금례,정용태,이귀임,정복연,김정한,정광훈1,조진욱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import openpyxl as op\n",
    "\n",
    "# Define Cohens'D\n",
    "def cohens_d(group1, group2):\n",
    "    mean1, mean2 = np.mean(group1), np.mean(group2)\n",
    "    std1, std2 = np.std(group1, ddof=1), np.std(group2, ddof=1)\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    pooled_std = np.sqrt(((n1 - 1) * std1**2 + (n2 - 1) * std2**2) / (n1 + n2 - 2))\n",
    "    return (mean1 - mean2) / pooled_std\n",
    "\n",
    "# 테스트 실행 함수\n",
    "def run_tests(before_mean, after_mean, band_name, wb, row, name):\n",
    "    print(f\"\\n=== {band_name} 대역 분석 결과 ===\")\n",
    "\n",
    "    # mean of before vs after\n",
    "    mean_before = np.mean(before_mean)\n",
    "    mean_after = np.mean(after_mean)\n",
    "    print(f\"mean_before: {mean_before}\")\n",
    "    print(f\"mean_after: {mean_after}\")\n",
    "\n",
    "    # Kolmogorov-Smirnov test\n",
    "    difference = before_mean - after_mean\n",
    "    ks_statistic, ks_p_value = stats.kstest(difference, stats.norm.cdf)\n",
    "    print(f\"KS Statistic: {ks_statistic}\")\n",
    "    print(f\"KS p-value: {ks_p_value}\")\n",
    "\n",
    "    # Paired t-test\n",
    "    t_stat, p_value = stats.ttest_rel(before_mean, after_mean)\n",
    "    print(f\"t_statistics: {t_stat}\")\n",
    "    print(f\"p-value: {p_value}\")\n",
    "\n",
    "    # Calculate Effect Size\n",
    "    effect_size = cohens_d(before_mean, after_mean)\n",
    "    print(f\"Effect size: {effect_size}\")\n",
    "\n",
    "    # Excel 저장\n",
    "    ws_b = wb[\"Sheet2\"]\n",
    "    band_row_offset = {\n",
    "        'Delta': -3,\n",
    "        'Theta': -2,\n",
    "        'Alpha': -1,\n",
    "        'Beta': 0,\n",
    "        'Gamma': 1\n",
    "    }\n",
    "    \n",
    "    row_b = row * 5 + band_row_offset.get(band_name)\n",
    "    if row_b is None:\n",
    "        print(f\"Invalid band name: {band_name}\")\n",
    "        return\n",
    "\n",
    "    ws_b.cell(row=row_b, column=1).value = name\n",
    "    ws_b.cell(row=row_b, column=4).value = mean_before\n",
    "    ws_b.cell(row=row_b, column=5).value = mean_after\n",
    "    ws_b.cell(row=row_b, column=6).value = ks_statistic\n",
    "    ws_b.cell(row=row_b, column=7).value = ks_p_value\n",
    "    ws_b.cell(row=row_b, column=9).value = t_stat\n",
    "    ws_b.cell(row=row_b, column=10).value = p_value\n",
    "    ws_b.cell(row=row_b, column=12).value = effect_size\n",
    "\n",
    "# Removing large artifact by band 함수 정의\n",
    "def remove_artifacts(before_mean, after_mean, large_artifact):\n",
    "    before_idx = set()\n",
    "    after_idx = set()\n",
    "\n",
    "    for t_start, t_end in large_artifact:\n",
    "        if t_start < 3600 and t_end < 3600:\n",
    "            before_idx.update(range(t_start*200, t_end*200))\n",
    "            after_idx.update(range(t_start*200, t_end*200))\n",
    "        elif t_start < 3600 and t_end >= 3600:\n",
    "            before_idx.update(range(t_start*200, 3600*200))\n",
    "            after_idx.update(range(t_start*200, 3600*200))\n",
    "            after_idx.update(range(0, (t_end-3600)*200))\n",
    "            before_idx.update(range(0, (t_end-3600)*200))\n",
    "        else:\n",
    "            after_idx.update(range((t_start-3600)*200, (t_end-3600)*200))\n",
    "            before_idx.update(range((t_start-3600)*200, (t_end-3600)*200))\n",
    "\n",
    "    before_idx = sorted(before_idx)\n",
    "    after_idx = sorted(after_idx)\n",
    "\n",
    "    return np.delete(before_mean, before_idx), np.delete(after_mean, after_idx)\n",
    "\n",
    "# Process band data 함수 정의\n",
    "def process_band_data(tfr_data, large_artifact):\n",
    "    start1, end1 = 0, 3599 * 200\n",
    "    start2, end2 = 3600 * 200, 7199 * 200\n",
    "\n",
    "    # Split before and after\n",
    "    before = tfr_data[:, :, start1:end1]\n",
    "    after = tfr_data[:, :, start2:end2]\n",
    "\n",
    "    # Average over channels and frequencies\n",
    "    before_mean_channel = before.mean(axis=0)\n",
    "    after_mean_channel = after.mean(axis=0)\n",
    "    \n",
    "    before_mean = before_mean_channel.mean(axis=0)\n",
    "    after_mean = after_mean_channel.mean(axis=0)\n",
    "\n",
    "    # Remove artifacts\n",
    "    return remove_artifacts(before_mean, after_mean, large_artifact)\n",
    "\n",
    "# Main 함수 정의\n",
    "def main():\n",
    "    # Initialize name dictionary\n",
    "    names = ['고정실', '김가람', '김득실', '김영현', '김충연', '민병춘1', '박주연1', '박주연2', '벌', \n",
    "             '안중훈', '윤병시', '이미우', '임석봉', '전창희', '정광훈2', '정금례', '정용태', '이귀임', \n",
    "             '정복연', '김정한', '정광훈1', '조진욱']\n",
    "    name_dict = {name: i+1 for i, name in enumerate(names)}\n",
    "\n",
    "    # Get analysis targets\n",
    "    name_list = input(\"분석대상 이름을 입력하세요. (여러명일 경우 쉼표로 구분)\").split(',')\n",
    "    print(f'분석대상은 {name_list}입니다.')\n",
    "\n",
    "    # Load workbook and artifact data\n",
    "    wb = op.load_workbook(r\"C:\\Users\\esin4\\OneDrive\\바탕 화면\\Github\\Mg_infusion_coma\\Mg_infusion_data.xlsx\")\n",
    "    large_artifact_data = pd.read_csv(r'C:\\Users\\esin4\\OneDrive\\바탕 화면\\Github\\Mg_infusion_coma\\large_artifact.csv', encoding='utf-8-sig')\n",
    "\n",
    "    # Process each name\n",
    "    for name in name_list:\n",
    "        print(f'{name}의 데이터를 분석합니다.')\n",
    "        \n",
    "        # Get large artifacts\n",
    "        large_artifact = []\n",
    "        if name in large_artifact_data['Name'].values:\n",
    "            coordinates = large_artifact_data[large_artifact_data['Name'] == name]['Coordinates'].values[0]\n",
    "            if coordinates != 'skip':\n",
    "                large_artifact = eval(coordinates)\n",
    "        print(f\"{name}의 large artifact: {large_artifact}\")\n",
    "\n",
    "        # Get row number\n",
    "        row = name_dict.get(name)\n",
    "        if row is None:\n",
    "            print(f\"{name}이(가) name_dict에 없습니다.\")\n",
    "            exit()\n",
    "\n",
    "        # Store band data in dictionary\n",
    "        tfr_data = {}\n",
    "        \n",
    "        # Load band data\n",
    "        for band in ['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma1', 'Gamma2']:\n",
    "            file_path = rf'H:\\Mg_EEG\\tfr_files_gamma\\{name}{band}_7200_tfr.h5'\n",
    "            tfr = mne.time_frequency.read_tfrs(file_path)\n",
    "            tfr_data[band] = tfr.data\n",
    "            del tfr\n",
    "        print(f\"{name}의 데이터를 불러왔습니다.\")\n",
    "\n",
    "        # Combine Gamma bands\n",
    "        if 'Gamma1' in tfr_data and 'Gamma2' in tfr_data:\n",
    "            tfr_data['Gamma'] = np.concatenate([tfr_data['Gamma1'], tfr_data['Gamma2']], axis=1)\n",
    "            del tfr_data['Gamma1'], tfr_data['Gamma2']\n",
    "        print(f\"{name}의 Gamma1과 Gamma2 데이터를 결합했습니다.\")\n",
    "\n",
    "        # Process each band\n",
    "        for band in ['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma']:\n",
    "            if band not in tfr_data:\n",
    "                print(f\"Warning: {band} data not found\")\n",
    "                exit()\n",
    "                \n",
    "            before_clean, after_clean = process_band_data(tfr_data[band], large_artifact)\n",
    "            print(f\"{band} 데이터의 artifact를 제거했습니다.\")\n",
    "            \n",
    "            run_tests(before_clean, after_clean, band, wb, row, name)\n",
    "            print(f\"{band} 데이터의 테스트를 실행했습니다.\")\n",
    "            \n",
    "            del tfr_data[band]\n",
    "            print(f\"{band} 데이터를 삭제했습니다.\")\n",
    "\n",
    "    # Save results\n",
    "    wb.save(r\"C:\\Users\\esin4\\OneDrive\\바탕 화면\\Github\\Mg_infusion_coma\\Mg_infusion_data.xlsx\")\n",
    "    print(f\"{name_list}의 데이터 분석결과를 저장했습니다.\")\n",
    "    print(f\"{name_list}의 데이터 분석이 완료되었습니다.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
