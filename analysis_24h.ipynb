{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plot\n",
    "import scipy.stats as stats\n",
    "import openpyxl as op\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing():\n",
    "    # EEG 불러오기      \n",
    "    try:\n",
    "        eeg_data = mne.io.read_raw_edf(file_path, preload=True)\n",
    "        eeg_data_raw = eeg_data.copy()\n",
    "        eeg_data_info = eeg_data.info\n",
    "        print(\"EEG를 불러왔습니다.\")\n",
    "        \n",
    "        # Bandpass filters\n",
    "        eeg_data.filter(l_freq=0.1, h_freq=90)\n",
    "        \n",
    "        # Notch filter apply\n",
    "        eeg_data.notch_filter(freqs=[60])\n",
    "        \n",
    "        # 채널명 표준화\n",
    "        eeg_data = eeg_data.drop_channels(eeg_data.ch_names[18:])\n",
    "        eeg_data_ch_names = eeg_data.ch_names\n",
    "        channel_mapping = {}\n",
    "        for i in range(len(eeg_data_ch_names)):\n",
    "            if eeg_data_ch_names[i] != ch_names_answer[i]:  # 차이가 있는 경우, 해당 인덱스의 값을 딕셔너리에 저장\n",
    "                channel_mapping[eeg_data_ch_names[i]] = ch_names_answer[i]\n",
    "        \n",
    "        print(f\"{variable_name}의 잘못된 채널명은 {channel_mapping} 입니다.\")\n",
    "        eeg_data.rename_channels(channel_mapping)\n",
    "        print(\"채널명 표준화가 완료되었습니다.\")\n",
    "        \n",
    "        # monopolar data로 변형\n",
    "        monopolar_data = np.dot(transform_mat, eeg_data.get_data())  # monopolar 계산\n",
    "        monopolar_info = mne.create_info(\n",
    "            ch_names=monopolar_chs,\n",
    "            sfreq=eeg_data.info['sfreq'],\n",
    "            ch_types='eeg'\n",
    "        )  # 새로운 info 생성\n",
    "        eeg_data_monopolar = mne.io.RawArray(monopolar_data, monopolar_info)  # 새 monopolar 데이터 생성\n",
    "        montage = mne.channels.make_standard_montage('standard_1020')\n",
    "        eeg_data_monopolar.set_montage(montage)  # 몽타주 부여\n",
    "        print(\"monopolar 데이터가 형성되었습니다.\")\n",
    "        \n",
    "        # ICA 시행\n",
    "        ica = mne.preprocessing.ICA(n_components=15, random_state=42)\n",
    "        ica.fit(eeg_data_monopolar)\n",
    "        muscle_idx, muscle_scores = ica.find_bads_muscle(eeg_data_monopolar)\n",
    "        eeg_data_clean = eeg_data_monopolar.copy()\n",
    "        ica.apply(eeg_data_clean, exclude=muscle_idx)\n",
    "        print(f\"{variable_name}의 ICA가 종료되었습니다.\")\n",
    "        \n",
    "        # preprocessing info 저장\n",
    "        info[variable_name] = (eeg_data_raw, eeg_data_info, eeg_data_clean)        \n",
    "\n",
    "        # clean data 파일로 저장\n",
    "        try: \n",
    "            eeg_data_clean.save(rf'E:\\Mg_EEG\\edf_subacute\\{variable_name}_clean.fif', overwrite=False)\n",
    "            print(f\"{variable_name}의 clean data가 저장되었습니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"{variable_name}의 clean data 저장 중 오류가 발생했습니다: {str(e)}\")\n",
    "        \n",
    "        return eeg_data_clean\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"{variable_name} 처리 중 오류가 발생했습니다: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFR_analysis (eeg_data_clean):\n",
    "    \n",
    "    # bad channel 정보 확인    \n",
    "    bad_channel_value = subacute_data.loc[subacute_data['name'] == name][day].values[0]\n",
    "    if bad_channel_value == 'O':\n",
    "        bad_channels_list = []\n",
    "        print(f\"{variable_name}의 bad channel은 없습니다.\")\n",
    "    elif bad_channel_value == 'X':\n",
    "        raise ValueError(\"X 값이므로 오류 발생\")\n",
    "    else:\n",
    "        bad_channels_list = [\n",
    "            channel.strip() \n",
    "            for channel in bad_channel_value.split(',')\n",
    "        ]\n",
    "        print(f\"{variable_name}의 bad channel은 {bad_channels_list} 입니다.\")\n",
    "    \n",
    "\n",
    "    # bad channels 제거\n",
    "    eeg_data_clean = eeg_data_clean.copy()\n",
    "    eeg_data_clean.drop_channels(bad_channels_list)\n",
    "\n",
    "    # 대역별 TFR 시행\n",
    "    tfr_dict = {} # 대역별 tfr 결과 저장\n",
    "    for band, (fmin, fmax) in freq_ranges.items():\n",
    "        \n",
    "        # TFR 분석\n",
    "        print(f\"{variable_name}의 {band}대역의 TFR 분석이 시작되었습니다.\")\n",
    "        try:\n",
    "            tfr = eeg_data_clean.compute_tfr(method='multitaper', freqs=np.arange(fmin, fmax+1), n_jobs=-1, reject_by_annotation=False)\n",
    "            tfr_dict[band] = tfr.data\n",
    "            print(f\"{variable_name}의 {band} 대역의 TFR  분석이 종료되었습니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"{variable_name}의 {band} 대역의 TFR  분석 중 오류가 발생하였습니다: {str(e)}\")\n",
    "        \n",
    "        # TFR 저장\n",
    "        saving_path = rf'E:\\Mg_EEG\\tfr_files_subacute\\{variable_name}_{band}_tfr.h5'\n",
    "        try:\n",
    "            tfr.save(saving_path, overwrite=False)\n",
    "            print(f\"TFR 파일이 성공적으로 저장되었습니다.\")     \n",
    "        except Exception as e:\n",
    "            print(f\"TFR 파일 저장 중 오류가 발생하였습니다: {str(e)}\")\n",
    "\n",
    "        # Delete tfr for memory\n",
    "        del tfr\n",
    "        print(f\"{name}의 데이터를 메모리에서 삭제하였습니다.\")\n",
    "        gc.collect()\n",
    "\n",
    "    return tfr_dict\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_analysis ():\n",
    "    \n",
    "    # Combine Gamma bands\n",
    "    try:\n",
    "        if 'Gamma1' in tfr_dict and 'Gamma2' in tfr_dict:\n",
    "            tfr_dict['Gamma'] = np.concatenate([tfr_dict['Gamma1'], tfr_dict['Gamma2']], axis=1)\n",
    "            del tfr_dict['Gamma1'], tfr_dict['Gamma2']\n",
    "        print(f\"{name}의 Gamma1과 Gamma2 데이터를 결합했습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Gamma 데이터 결합 과정에서 오류가 발생하였습니다: {str(e)}\")\n",
    "\n",
    "    # 밴드의 평균 파워 계산\n",
    "    for band in ['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma']:\n",
    "        mean = tfr_dict[band].mean(axis=0) # 18개 채널에 대한 평균\n",
    "        mean = mean.mean(axis=0) # 대역 내 주파수에 대한 평균\n",
    "        mean = mean.mean(axis=0) # 5분의 파워 평균\n",
    "        print(f\"{name}_{day}_{band}의 평균값은 {mean} 입니다.\")\n",
    "\n",
    "        # 엑셀에 저장     \n",
    "        try:\n",
    "            ws_b = wb['subacute']\n",
    "            name_row_offset = name_dict.get(name)\n",
    "            day_row_offset = {\n",
    "                'day1': 1,\n",
    "                'day3': 2\n",
    "            }\n",
    "            band_row_offset = {\n",
    "                'Delta': -13,\n",
    "                'Theta': -12,\n",
    "                'Alpha': -11,\n",
    "                'Beta': -10,\n",
    "                'Gamma': -9\n",
    "            }\n",
    "            \n",
    "            row_b = name_row_offset * 10 + day_row_offset.get(day) * 5 + band_row_offset.get(band)        \n",
    "        \n",
    "            if row_b is None:\n",
    "                print(f\"Invalid band name: {band_name}\")\n",
    "                return   \n",
    "            ws_b.cell(row=row_b, column=1).value = name \n",
    "            ws_b.cell(row=row_b, column=2).value = day\n",
    "            ws_b.cell(row=row_b, column=3).value = band\n",
    "            ws_b.cell(row=row_b, column=4).value = mean\n",
    "            print(f\"{variable_name}의 {band} 데이터가 저장되었습니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"{variable_name}의 {band} 데이터 저장 과정 중 오류가 발생하였습니다: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 설정값들 모음\n",
    "\n",
    "ch_names_answer = ['Fp1-F3', 'F3-C3', 'C3-P3', 'P3-O1', \n",
    "                'Fp2-F4', 'F4-C4', 'C4-P4', 'P4-O2', \n",
    "                'Fp1-F7', 'F7-T3', 'T3-T5', 'T5-O1', \n",
    "                'Fp2-F8', 'F8-T4', 'T4-T6', 'T6-O2', \n",
    "                'Fz-Cz', 'Cz-Pz']\n",
    "\n",
    "bipolar_chs = ['Fp1-F3', 'F3-C3', 'C3-P3', 'P3-O1', \n",
    "                'Fp2-F4', 'F4-C4', 'C4-P4', 'P4-O2', \n",
    "                'Fp1-F7', 'F7-T3', 'T3-T5', 'T5-O1', \n",
    "                'Fp2-F8', 'F8-T4', 'T4-T6', 'T6-O2', \n",
    "                'Fz-Cz', 'Cz-Pz']\n",
    "\n",
    "monopolar_chs = ['Fp1', 'F3', 'C3', 'P3', 'O1',\n",
    "                 'Fp2', 'F4', 'C4', 'P4', 'O2',\n",
    "                 'F7', 'T3', 'T4', 'T5', 'T6', 'F8',\n",
    "                 'Fz', 'Cz', 'Pz']\n",
    "\n",
    "n_bipolar = len(bipolar_chs)\n",
    "n_monopolar = len(monopolar_chs)\n",
    "transform_mat = np.zeros((n_monopolar, n_bipolar))\n",
    "\n",
    "for i, mono_ch in enumerate(monopolar_chs):\n",
    "    for j, bi_ch in enumerate(bipolar_chs):\n",
    "        if mono_ch in bi_ch.split('-'):\n",
    "            if mono_ch == bi_ch.split('-')[0]:\n",
    "                transform_mat[i, j] = 1\n",
    "            else:\n",
    "                transform_mat[i, j] = -1\n",
    "\n",
    "subacute_data = pd.read_excel(r\"C:\\Users\\Brain_Science\\Documents\\GitHub\\Mg_infusion_coma\\subacute_data.xlsx\", sheet_name='Sheet1')\n",
    "\n",
    "# 각 주파수 대역의 정보\n",
    "freq_ranges = {\n",
    "    'Delta': (1, 4),\n",
    "    'Theta': (4, 8),\n",
    "    'Alpha': (8, 13),\n",
    "    'Beta': (13, 30),\n",
    "    'Gamma1': (30, 60),\n",
    "    'Gamma2': (61, 90) # Gamma 대역은 해당하는 주파수가 너무 넓기에 2개로 나누어서 분석하고, 추후 결합함\n",
    "}\n",
    "\n",
    "# Initialize name dictionary\n",
    "names = ['고정실', '김가람', '김득실', '김영현', '김충연', '민병춘', '박주연', '벌', \n",
    "            '안중훈', '윤병시', '이미우', '임석봉', '전창희', '정금례', '정용태', '이귀임', \n",
    "            '정복연', '김정한', '정광훈', '조진욱']\n",
    "name_dict = {name: i+1 for i, name in enumerate(names)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "고정실,김가람,김득실,김영현,김충연,민병춘,박주연,벌,안중훈,윤병시,이미우,임석봉,전창희,정금례,정용태,이귀임,정복연,김정한,정광훈,조진욱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분석대상은 _day1 입니다.\n",
      "_day1의 EDF 파일이 존재하지 않습니다.\n",
      "분석대상은 _day3 입니다.\n",
      "_day3의 EDF 파일이 존재하지 않습니다.\n",
      "의 분석이 완료되었습니다.\n",
      "['']의 분석결과를 엑셀에 저장하였습니다.\n",
      "['']의 데이터 분석이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "name_list = input(\"분석대상 이름을 입력하세요. (여러명일 경우 쉼표로 구분)\").split(',')\n",
    "day_list = [\"day1\", \"day3\"]\n",
    "# 엑셀 위치\n",
    "wb = op.load_workbook(r\"C:\\Users\\Brain_Science\\Documents\\GitHub\\Mg_infusion_coma\\Mg_infusion_data.xlsx\")\n",
    "info = {}\n",
    "\n",
    "for name in name_list:\n",
    "    for day in day_list:\n",
    "        # 분석대상 설정\n",
    "        variable_name = f\"{name}_{day}\"\n",
    "        print(f\"분석대상은 {variable_name} 입니다.\")       \n",
    "        \n",
    "        # 파일 존재 여부 확인\n",
    "        file_path = rf\"E:\\Mg_EEG\\edf_subacute\\{variable_name}.EDF\"\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"{variable_name}의 EDF 파일이 존재하지 않습니다.\")\n",
    "            continue # 파일 존재하지 않으면 다음으로 넘어감\n",
    "        \n",
    "        # preprocessing 시행\n",
    "        eeg_data_clean = preprocessing()\n",
    "        if eeg_data_clean is None:\n",
    "            print(f\"{variable_name}의 preprocessing에 실패했습니다.\")\n",
    "            continue\n",
    "        \n",
    "        # 대역별 TFR 시행\n",
    "        tfr_dict = TFR_analysis(eeg_data_clean)\n",
    "\n",
    "        # power analysis 시행\n",
    "        power_analysis()\n",
    "\n",
    "        print(f\"{variable_name}의 분석이 완료되었습니다.\")\n",
    "    print(f\"{name}의 분석이 완료되었습니다.\")\n",
    "# 엑셀에 저장\n",
    "wb.save(r\"C:\\Users\\Brain_Science\\Documents\\GitHub\\Mg_infusion_coma\\Mg_infusion_data.xlsx\")\n",
    "\n",
    "print(f\"{name_list}의 분석결과를 엑셀에 저장하였습니다.\")\n",
    "print(f\"{name_list}의 데이터 분석이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분석대상은 윤병시_day1 입니다.\n",
      "Extracting EDF parameters from E:\\Mg_EEG\\edf_subacute\\윤병시_day1.EDF...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 60199  =      0.000 ...   300.995 secs...\n",
      "EEG를 불러왔습니다.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.1 - 90 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.10\n",
      "- Lower transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 0.05 Hz)\n",
      "- Upper passband edge: 90.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 95.00 Hz)\n",
      "- Filter length: 6601 samples (33.005 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 59 - 61 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 59.35\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 59.10 Hz)\n",
      "- Upper passband edge: 60.65 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 60.90 Hz)\n",
      "- Filter length: 1321 samples (6.605 s)\n",
      "\n",
      "윤병시_day1의 잘못된 채널명은 {'FZ-CZ': 'Fz-Cz', 'CZ-PZ': 'Cz-Pz'} 입니다.\n",
      "채널명 표준화가 완료되었습니다.\n",
      "Creating RawArray with float64 data, n_channels=19, n_times=60200\n",
      "    Range : 0 ... 60199 =      0.000 ...   300.995 secs\n",
      "Ready.\n",
      "monopolar 데이터가 형성되었습니다.\n",
      "Fitting ICA to data using 19 channels (please be patient, this may take a while)\n",
      "Selecting by number: 15 components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "C:\\Users\\Brain_Science\\AppData\\Local\\Temp\\ipykernel_26012\\522455965.py:41: RuntimeWarning: The data has not been high-pass filtered. For good ICA performance, it should be high-pass filtered (e.g., with a 1.0 Hz lower bound) before fitting ICA.\n",
      "  ica.fit(eeg_data_monopolar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA took 0.7s.\n",
      "Effective window size : 10.240 (s)\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (15 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 19 PCA components\n",
      "윤병시_day1의 ICA가 종료되었습니다.\n",
      "Writing E:\\Mg_EEG\\edf_subacute\\윤병시_day1_clean.fif\n",
      "Closing E:\\Mg_EEG\\edf_subacute\\윤병시_day1_clean.fif\n",
      "[done]\n",
      "윤병시_day1의 clean data가 저장되었습니다.\n",
      "윤병시_day1의 bad channel은 없습니다.\n",
      "윤병시_day1의 Delta대역의 TFR 분석이 시작되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brain_Science\\AppData\\Local\\Temp\\ipykernel_26012\\522455965.py:52: RuntimeWarning: This filename (E:\\Mg_EEG\\edf_subacute\\윤병시_day1_clean.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  eeg_data_clean.save(rf'E:\\Mg_EEG\\edf_subacute\\{variable_name}_clean.fif', overwrite=False)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  19 | elapsed:    0.1s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  19 | elapsed:    0.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  19 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  19 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "윤병시_day1의 Delta 대역의 TFR  분석이 종료되었습니다.\n",
      "TFR 파일 저장 중 오류가 발생하였습니다: Destination file exists. Please use option \"overwrite=True\" to force overwriting.\n",
      "윤병시의 데이터를 메모리에서 삭제하였습니다.\n",
      "윤병시_day1의 Theta대역의 TFR 분석이 시작되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of  19 | elapsed:    0.3s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  19 | elapsed:    0.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  19 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  19 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "윤병시_day1의 Theta 대역의 TFR  분석이 종료되었습니다.\n",
      "TFR 파일 저장 중 오류가 발생하였습니다: Destination file exists. Please use option \"overwrite=True\" to force overwriting.\n",
      "윤병시의 데이터를 메모리에서 삭제하였습니다.\n",
      "윤병시_day1의 Alpha대역의 TFR 분석이 시작되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of  19 | elapsed:    0.3s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  19 | elapsed:    0.4s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  19 | elapsed:    0.4s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  19 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "윤병시_day1의 Alpha 대역의 TFR  분석이 종료되었습니다.\n",
      "TFR 파일 저장 중 오류가 발생하였습니다: Destination file exists. Please use option \"overwrite=True\" to force overwriting.\n",
      "윤병시의 데이터를 메모리에서 삭제하였습니다.\n",
      "윤병시_day1의 Beta대역의 TFR 분석이 시작되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of  19 | elapsed:    1.1s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  19 | elapsed:    1.1s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  19 | elapsed:    1.2s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  19 | elapsed:    1.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "윤병시_day1의 Beta 대역의 TFR  분석이 종료되었습니다.\n",
      "TFR 파일 저장 중 오류가 발생하였습니다: Destination file exists. Please use option \"overwrite=True\" to force overwriting.\n",
      "윤병시의 데이터를 메모리에서 삭제하였습니다.\n",
      "윤병시_day1의 Gamma1대역의 TFR 분석이 시작되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  19 | elapsed:    1.8s remaining:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  19 | elapsed:    2.0s remaining:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  19 | elapsed:    2.0s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  19 | elapsed:    2.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "윤병시_day1의 Gamma1 대역의 TFR  분석이 종료되었습니다.\n",
      "TFR 파일 저장 중 오류가 발생하였습니다: Destination file exists. Please use option \"overwrite=True\" to force overwriting.\n",
      "윤병시의 데이터를 메모리에서 삭제하였습니다.\n",
      "윤병시_day1의 Gamma2대역의 TFR 분석이 시작되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of  19 | elapsed:    1.8s remaining:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  19 | elapsed:    1.8s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  19 | elapsed:    1.9s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  19 | elapsed:    1.9s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "윤병시_day1의 Gamma2 대역의 TFR  분석이 종료되었습니다.\n",
      "TFR 파일 저장 중 오류가 발생하였습니다: Destination file exists. Please use option \"overwrite=True\" to force overwriting.\n",
      "윤병시의 데이터를 메모리에서 삭제하였습니다.\n",
      "윤병시의 Gamma1과 Gamma2 데이터를 결합했습니다.\n",
      "윤병시_day1_Delta의 평균값은 1.3368147272665006e-09 입니다.\n",
      "윤병시_day1의 Delta 데이터가 저장되었습니다.\n",
      "윤병시_day1_Theta의 평균값은 2.9265551831156167e-10 입니다.\n",
      "윤병시_day1의 Theta 데이터가 저장되었습니다.\n",
      "윤병시_day1_Alpha의 평균값은 7.435714482094691e-11 입니다.\n",
      "윤병시_day1의 Alpha 데이터가 저장되었습니다.\n",
      "윤병시_day1_Beta의 평균값은 2.359658619416742e-11 입니다.\n",
      "윤병시_day1의 Beta 데이터가 저장되었습니다.\n",
      "윤병시_day1_Gamma의 평균값은 3.6161816209363967e-12 입니다.\n",
      "윤병시_day1의 Gamma 데이터가 저장되었습니다.\n",
      "윤병시_day1의 분석이 완료되었습니다.\n",
      "윤병시의 분석이 완료되었습니다.\n",
      "['윤병시']의 분석결과를 엑셀에 저장하였습니다.\n",
      "['윤병시']의 데이터 분석이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 재분석 돌리는 코드\n",
    "\n",
    "name_list = input(\"분석대상 이름을 입력하세요. (여러명일 경우 쉼표로 구분)\").split(',')\n",
    "day_list = [\"day1\"]\n",
    "# 엑셀 위치\n",
    "# wb = op.load_workbook(r\"C:\\Users\\Brain_Science\\Desktop\\new.xlsx\")\n",
    "info = {}\n",
    "\n",
    "for name in name_list:\n",
    "    for day in day_list:\n",
    "        # 분석대상 설정\n",
    "        variable_name = f\"{name}_{day}\"\n",
    "        print(f\"분석대상은 {variable_name} 입니다.\")       \n",
    "        \n",
    "        # 파일 존재 여부 확인\n",
    "        file_path = file_path = rf\"E:\\Mg_EEG\\edf_subacute\\{variable_name}.EDF\"\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"{variable_name}의 EDF 파일이 존재하지 않습니다.\")\n",
    "            continue # 파일 존재하지 않으면 다음으로 넘어감\n",
    "        \n",
    "        # preprocessing 시행\n",
    "        eeg_data_clean = preprocessing()\n",
    "        if eeg_data_clean is None:\n",
    "            print(f\"{variable_name}의 preprocessing에 실패했습니다.\")\n",
    "            continue\n",
    "        \n",
    "        # 대역별 TFR 시행\n",
    "        tfr_dict = TFR_analysis(eeg_data_clean)\n",
    "\n",
    "        # power analysis 시행\n",
    "        power_analysis()\n",
    "\n",
    "        print(f\"{variable_name}의 분석이 완료되었습니다.\")\n",
    "    print(f\"{name}의 분석이 완료되었습니다.\")\n",
    "# 엑셀에 저장\n",
    "# wb.save(r\"C:\\Users\\Brain_Science\\Desktop\\new.xlsx\")\n",
    "\n",
    "print(f\"{name_list}의 분석결과를 엑셀에 저장하였습니다.\")\n",
    "print(f\"{name_list}의 데이터 분석이 완료되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
