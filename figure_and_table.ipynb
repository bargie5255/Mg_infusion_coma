{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import mne\n",
    "import openpyxl as op\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnesium = pd.read_excel(r\"D:\\주성\\documents\\2025\\Mg comma\\clinical features2.xlsx\", sheet_name='Table2')\n",
    "magnesium1 = magnesium.loc[magnesium['Mg Protocol Type']==1]\n",
    "magnesium2 = magnesium.loc[magnesium['Mg Protocol Type']==2]\n",
    "print(magnesium1.describe())\n",
    "print(magnesium2.describe())\n",
    "\n",
    "from scipy.stats import mannwhitneyu as mann\n",
    "for col in ['Mg Starting Date', 'Mg Infusion Day', 'Loading Mg', 'Maintenance Mg', 'Total Mg', 'Max concentration']:\n",
    "    s, p = mann(magnesium1[col], magnesium2[col])\n",
    "    print(col, s, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm  # For colormap\n",
    "\n",
    "# Load data\n",
    "file_path = r\"D:\\주성\\documents\\2025\\Mg comma\\차트리뷰\\clinical features9.xlsx\"\n",
    "sheet_name_power = 'pharmacoEEG'\n",
    "sheet_name_feature = 'clinical_data'\n",
    "\n",
    "df = pd.read_excel(file_path, sheet_name=sheet_name_power)\n",
    "response = pd.read_excel(file_path, sheet_name=sheet_name_feature)[['Patient No.', 'response_10']]\n",
    "response.rename(columns={\"Patient No.\": \"ID\", \"response_10\": 'response'}, inplace=True)\n",
    "df = df.merge(response, on='ID', how='left')\n",
    "\n",
    "# Extract unique bands\n",
    "bands = df[\"band\"].unique()\n",
    "\n",
    "# Set colormap (True = Blue scale, False = Red scale)\n",
    "cmap_true = cm.get_cmap(\"Blues\")  # Response=True group\n",
    "cmap_false = cm.get_cmap(\"Reds\")  # Response=False group\n",
    "\n",
    "# Assign rankings separately for each band\n",
    "df[\"rank_true\"] = np.nan\n",
    "df[\"rank_false\"] = np.nan\n",
    "\n",
    "for band in bands:\n",
    "    band_data = df[df[\"band\"] == band]\n",
    "\n",
    "    # Rank within each band separately\n",
    "    true_group = band_data[band_data[\"response\"] == True]\n",
    "    if not true_group.empty:\n",
    "        df.loc[true_group.index, \"rank_true\"] = true_group[\"post_change\"].abs().rank(method=\"min\", pct=True)\n",
    "\n",
    "    false_group = band_data[band_data[\"response\"] == False]\n",
    "    if not false_group.empty:\n",
    "        df.loc[false_group.index, \"rank_false\"] = false_group[\"post_change\"].abs().rank(method=\"min\", pct=True)\n",
    "\n",
    "# Plot change rate trends for each band\n",
    "for band in bands:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))  # Define Axes explicitly\n",
    "    \n",
    "    # Filter data for the current band\n",
    "    band_data = df[df[\"band\"] == band]\n",
    "\n",
    "    # Plot individual patient change rates\n",
    "    for _, row in band_data.iterrows():\n",
    "        patient_id = row[\"ID\"]\n",
    "        pre_change = 0  # Pre-timepoint is always 0\n",
    "        post_change = row[\"post_change\"]\n",
    "        day1_change = row[\"day1_change\"]\n",
    "        response_status = row[\"response\"]\n",
    "\n",
    "        # Assign colors based on rank within each band\n",
    "        if response_status:\n",
    "            norm_value = row[\"rank_true\"] if not pd.isna(row[\"rank_true\"]) else 0.5  # Default to mid-value\n",
    "            color = cmap_true(norm_value)\n",
    "        else:\n",
    "            norm_value = row[\"rank_false\"] if not pd.isna(row[\"rank_false\"]) else 0.5  # Default to mid-value\n",
    "            color = cmap_false(norm_value)\n",
    "\n",
    "        # Adjust line thickness based on rank\n",
    "        line_width = 1 + (norm_value * 4)  # Minimum width 1, max width 5\n",
    "        marker_size = 6  # Keep marker size constant\n",
    "\n",
    "        # Plot the change rate\n",
    "        ax.plot([\"pre\", \"post\", \"day1\"], [pre_change, post_change, day1_change],\n",
    "                 marker='o', linestyle='-', color=color, linewidth=line_width, markersize=marker_size, alpha=0.8)\n",
    "\n",
    "    # Set plot title and labels\n",
    "    ax.set_title(f\"Change Rate Trend - {band} Band (Rank-based Coloring)\", fontsize=14)\n",
    "    ax.set_xlabel(\"Time\", fontsize=12)\n",
    "    ax.set_ylabel(\"Change Rate\", fontsize=12)\n",
    "    ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax.grid(True)\n",
    "\n",
    "    # ✅ Set colorbar with actual percentile rank\n",
    "    sm_true = cm.ScalarMappable(cmap=cmap_true, norm=plt.Normalize(vmin=0, vmax=1))\n",
    "    sm_false = cm.ScalarMappable(cmap=cmap_false, norm=plt.Normalize(vmin=0, vmax=1))\n",
    "\n",
    "    # ✅ Adjust colorbar labels for correct rank representation\n",
    "    cbar_true = plt.colorbar(sm_true, ax=ax, fraction=0.03, pad=0.02)\n",
    "    cbar_true.set_label(\"Percentile Rank (Response: True)\")\n",
    "\n",
    "    cbar_false = plt.colorbar(sm_false, ax=ax, fraction=0.03, pad=0.06)\n",
    "    cbar_false.set_label(\"Percentile Rank (Response: False)\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"D:\\주성\\documents\\2025\\Mg comma\\차트리뷰\\clinical features9.xlsx\"\n",
    "sheet_name = 'pharmacoEEG'\n",
    "\n",
    "df = pd.read_excel(file_path, sheet_name = sheet_name)\n",
    "\n",
    "# 밴드별로 데이터 분리하기\n",
    "bands = df['band'].unique()  # 모든 고유한 밴드 값 추출\n",
    "\n",
    "# 그래프 스타일 설정\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# 밴드 이름 첫 글자 대문자로 변경하는 함수\n",
    "def capitalize_band(band_name):\n",
    "    return band_name.capitalize()\n",
    "\n",
    "# 큰 도표 생성 (3x2 그리드)\n",
    "fig, axes = plt.subplots(3, 2, figsize=(18, 15))\n",
    "axes = axes.flatten()  # 2D 배열을 1D로 변환하여 접근 용이하게 함\n",
    "\n",
    "# 각 밴드별 그래프 생성 (첫 5개 서브플롯)\n",
    "for i, band in enumerate(bands[:5]):  # 5개 밴드까지만 처리\n",
    "    # 해당 밴드의 데이터만 필터링\n",
    "    band_data = df[df['band'] == band].copy()\n",
    "    \n",
    "    # 각 환자 ID별 데이터 시각화\n",
    "    for patient_id in band_data['ID'].unique():\n",
    "        patient_data = band_data[band_data['ID'] == patient_id]\n",
    "        \n",
    "        # 시간 포인트를 x축으로 사용하기 위한 데이터 준비\n",
    "        time_points = ['pre', 'post', 'day1']\n",
    "        changes = [\n",
    "            0,  # pre는 기준점이므로 변화율은 0\n",
    "            patient_data['post_change'].values[0] if not patient_data['post_change'].isna().all() else np.nan,\n",
    "            patient_data['day1_change'].values[0] if not patient_data['day1_change'].isna().all() else np.nan\n",
    "        ]\n",
    "        \n",
    "        # 결측치가 있는 부분은 점선으로 표시\n",
    "        valid_indices = ~np.isnan(changes)\n",
    "        \n",
    "        # 선 그래프로 표시 (결측치가 없는 부분)\n",
    "        axes[i].plot(\n",
    "            np.array(time_points)[valid_indices], \n",
    "            np.array(changes)[valid_indices], \n",
    "            marker='o', \n",
    "            label=f'ID: {patient_id}'\n",
    "        )\n",
    "        \n",
    "        # 결측치가 있는 경우 점선으로 연결\n",
    "        if not all(valid_indices):\n",
    "            for j in range(len(time_points)-1):\n",
    "                if valid_indices[j] and valid_indices[j+1]:\n",
    "                    continue  # 두 지점 모두 유효하면 실선으로 이미 그려짐\n",
    "                if valid_indices[j] or valid_indices[j+1]:  # 적어도 하나는 유효\n",
    "                    axes[i].plot(\n",
    "                        [time_points[j], time_points[j+1]], \n",
    "                        [changes[j], changes[j+1]], \n",
    "                        linestyle='--', \n",
    "                        alpha=0.5, \n",
    "                        color='gray'\n",
    "                    )\n",
    "    \n",
    "    # 그래프 꾸미기\n",
    "    axes[i].axhline(y=0, color='black', linestyle='-', alpha=0.3)  # 0 기준선 추가\n",
    "    axes[i].set_title(f'{capitalize_band(band)} Band Power Change Rate by Patient ID')\n",
    "    axes[i].set_xlabel('Time Point')\n",
    "    axes[i].set_ylabel('Relative Change in Power (%)')\n",
    "    axes[i].set_xticks(range(len(time_points)))\n",
    "    axes[i].set_xticklabels(time_points)\n",
    "    \n",
    "    # 환자 ID가 많은 경우 범례를 그래프 밖에 표시하지 않고 제외\n",
    "    if len(band_data['ID'].unique()) <= 10:\n",
    "        axes[i].legend(fontsize='small')\n",
    "\n",
    "# 마지막 서브플롯(6번째)에 박스플롯 두 개 그리기\n",
    "# Post 변화율에 대한 박스플롯\n",
    "box_data = pd.melt(df, id_vars=['band'], value_vars=['post_change', 'day1_change'], \n",
    "                   var_name='time_point', value_name='change_rate')\n",
    "box_data['time_point'] = box_data['time_point'].map({'post_change': 'Post', 'day1_change': 'Day 1'})\n",
    "\n",
    "# 밴드 이름 첫 글자 대문자로 변경\n",
    "box_data['band'] = box_data['band'].apply(capitalize_band)\n",
    "\n",
    "sns.boxplot(x='band', y='change_rate', hue='time_point', data=box_data, ax=axes[5])\n",
    "axes[5].set_title('Change Rate by Band and Time Point')\n",
    "axes[5].set_xlabel('Band')\n",
    "axes[5].set_ylabel('Relative Change in Power')\n",
    "axes[5].axhline(y=0, color='red', linestyle='--')\n",
    "axes[5].legend(title='Time Point')\n",
    "\n",
    "# 전체 레이아웃 조정\n",
    "plt.tight_layout()\n",
    "plt.savefig('all_bands_change_rate.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이전 버전의 post의 relative power에 대한 오름차순 막대그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"E:\\주성\\documents\\2025\\Mg comma\\data2.csv\")\n",
    "\n",
    "# CSV 파일 읽기\n",
    "data = df\n",
    "\n",
    "# 밴드별로 데이터 나누기\n",
    "bands = ['delta', 'theta', 'alpha', 'beta', 'gamma']\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for idx, band in enumerate(bands, 1):\n",
    "    plt.subplot(2, 3, idx)\n",
    "    \n",
    "    # 해당 밴드의 데이터만 추출\n",
    "    band_data = data[data['band'] == band].copy()\n",
    "    \n",
    "    # 변화율 계산 ((post - pre) / pre)\n",
    "    change = (band_data['mean_post_infusion'] - band_data['mean_pre_infusion']) / band_data['mean_pre_infusion']\n",
    "    \n",
    "    # 오름차순 정렬\n",
    "    sorted_change = np.sort(change)\n",
    "    \n",
    "    # 바 차트 그리기\n",
    "    plt.bar(range(len(sorted_change)), sorted_change)\n",
    "    plt.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    plt.title(f'{band.capitalize()} Band')\n",
    "    plt.ylim(-1, 2)  # y축 범위 수정\n",
    "\n",
    "plt.suptitle('Power Change by Frequency Band', fontsize=14, y=1.02)    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비율 만드는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clinical feature\n",
    "feature = pd.read_excel(r\"E:\\주성\\documents\\2025\\Mg comma\\clinical features5.xlsx\", sheet_name = 'Sheet1')\n",
    "feature = feature.iloc[:-2, :]\n",
    "\n",
    "# 파생변수 \n",
    "feature['Immunotherapy'] = ~feature['Immunotherapy Medications'].isna()\n",
    "feature['CIVADs'] = ~feature['CIVAD Medications'].isna()\n",
    "feature['STESS_5'] = feature['STESS'] >= 5\n",
    "feature['mRS_4'] = feature['mRS_premorbid'] >= 4\n",
    "feature['CIVADs_num'] = feature['CIVAD Medications'].apply(lambda x: sum(1 for c in str(x) if c.isupper()) if pd.notna(x) else 0)\n",
    "feature['Age_65'] = feature['Age'] >=65\n",
    "feature['Mg_change'] = feature['max_Mg_conc'] - feature['Mg_baseline']\n",
    "feature['Mg_8.5'] = feature['max_Mg_conc'] >= 8.5\n",
    "feature['mRS_Discharge_4'] = feature['mRS_Discharge'] >= 4\n",
    "\n",
    "# Total subject\n",
    "total_subject = feature['response'].sum()\n",
    "print(\"total response subject:\", total_subject)\n",
    "\n",
    "# 범주형\n",
    "feature_cat = feature[['Class_SRSE', 'CIVADs', 'Sex', 'Immunotherapy',\n",
    "    'Class_NORSE', 'Mg type', 'STESS_5', 'mRS_4', 'Age_65', 'Etiology', \n",
    "    'Sz Type', 'Mg_8.5', 'mRS_Discharge_4', 'Inhospital_Mortality'\n",
    "]]\n",
    "\n",
    "for col in feature_cat.columns:\n",
    "    cross = pd.crosstab(feature_cat[col], feature['response'])\n",
    "    print(cross)\n",
    "\n",
    "# 연속형\n",
    "feature_num = feature[['CIVADs_num', 'AED_number', 'Age', 'STESS',  'mRS_premorbid', 'max_Mg_conc', 'Mg_change', 'response', 'mRS_Discharge', 'Hospital_days', 'SE_Duration']]\n",
    "print(\"responder\", \"\\n\", feature_num.loc[feature_num['response']==1].describe())\n",
    "print(\"non-responder\", \"\\n\", feature_num.loc[feature_num['response']==0].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "통계값 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clinical feature\n",
    "feature = pd.read_excel(r\"D:\\주성\\documents\\2025\\Mg comma\\clinical features8.xlsx\", sheet_name = 'Sheet1')\n",
    "feature = feature.iloc[:-2, :]\n",
    "\n",
    "# 파생변수 \n",
    "feature['Immunotherapy'] = ~feature['Immunotherapy Medications'].isna()\n",
    "feature['CIVADs'] = ~feature['CIVAD Medications'].isna()\n",
    "feature['STESS_5'] = feature['STESS'] >= 5\n",
    "feature['mRS_4'] = feature['mRS_premorbid'] >= 4\n",
    "feature['CIVADs_num'] = feature['CIVAD Medications'].apply(lambda x: sum(1 for c in str(x) if c.isupper()) if pd.notna(x) else 0)\n",
    "feature['Age_65'] = feature['Age'] >=65\n",
    "feature['Mg_change'] = feature['max_Mg_conc'] - feature['Mg_baseline']\n",
    "feature['Mg_8.5'] = feature['max_Mg_conc'] >= 8.5\n",
    "feature['mRS_Discharge_4'] = feature['mRS_Discharge'] >= 4\n",
    "\n",
    "# fisher exact test\n",
    "\n",
    "def fisher(table, alpha=0.05):\n",
    "    # Fisher’s Exact Test 수행\n",
    "    odds_ratio, p_value = stats.fisher_exact(table)\n",
    "    return p_value \n",
    "\n",
    "# chi square test\n",
    "def chisquare (table, alpha=0.05):\n",
    "    chi, p_value, dof, exp = stats.chi2_contingency(table)\n",
    "    return p_value\n",
    "\n",
    "feature_cat = feature[['Class_SRSE', 'CIVADs', 'Sex', 'Immunotherapy',\n",
    "    'Class_NORSE', 'Mg type', 'STESS_5', 'mRS_4', 'Age_65', 'Mg_8.5', 'mRS_Discharge_4', 'Inhospital_Mortality']]\n",
    "\n",
    "feature_mulvar = feature[['Etiology', 'Sz Type']]\n",
    "\n",
    "feature_num = feature[['CIVADs_num', 'AED_number', \n",
    "'Age', 'STESS',  'mRS_premorbid', 'max_Mg_conc', 'Mg_change', 'response_10', 'mRS_Discharge', 'Hospital_days', 'SE_Duration']]\n",
    "\n",
    "results = {}\n",
    "for col in feature_cat.columns:\n",
    "    table = pd.crosstab(feature_cat[col], feature['response_10'])\n",
    "    p_value = fisher(table)\n",
    "    results[col] = {'p-value': p_value}\n",
    "\n",
    "for col in feature_mulvar.columns:\n",
    "    table = pd.crosstab(feature_mulvar[col], feature['response_10'])\n",
    "    p_value = chisquare(table)\n",
    "    results[col] = {'p-value': p_value}\n",
    "\n",
    "for col in feature_num.columns:\n",
    "    x = feature_num.loc[feature_num['response_10']==True][col]\n",
    "    y = feature_num.loc[feature_num['response_10']==False][col]\n",
    "    statistics, p_value = stats.mannwhitneyu(x, y)\n",
    "    results[col] = {'p-value': p_value}\n",
    "\n",
    "result_df = pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yes-no 처리방법에 따른 차이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clinical feature\n",
    "feature = pd.read_excel(r\"D:\\주성\\documents\\2025\\Mg comma\\clinical features6.xlsx\", sheet_name = 'Sheet1')\n",
    "feature = feature.iloc[:-2, :]\n",
    "\n",
    "# 파생변수 \n",
    "feature['Immunotherapy'] = ~feature['Immunotherapy Medications'].isna()\n",
    "feature['CIVADs'] = ~feature['CIVAD Medications'].isna()\n",
    "feature['STESS_5'] = feature['STESS'] >= 5\n",
    "feature['mRS_4'] = feature['mRS_premorbid'] >= 4\n",
    "feature['CIVADs_num'] = feature['CIVAD Medications'].apply(lambda x: sum(1 for c in str(x) if c.isupper()) if pd.notna(x) else 0)\n",
    "feature['Age_65'] = feature['Age'] >=65\n",
    "feature['Mg_change'] = feature['max_Mg_conc'] - feature['Mg_baseline']\n",
    "feature['Mg_8.5'] = feature['max_Mg_conc'] >= 8.5\n",
    "feature['mRS_Discharge_4'] = feature['mRS_Discharge'] >= 4\n",
    "\n",
    "# fisher exact test\n",
    "\n",
    "def fisher(table, alpha=0.05):\n",
    "    # Fisher’s Exact Test 수행\n",
    "    odds_ratio, p_value = stats.fisher_exact(table)\n",
    "    return p_value \n",
    "\n",
    "# chi square test\n",
    "def chisquare (table, alpha=0.05):\n",
    "    chi, p_value, dof, exp = stats.chi2_contingency(table)\n",
    "    return p_value\n",
    "\n",
    "feature_cat = feature[['Class_SRSE', 'CIVADs', 'Sex', 'Immunotherapy',\n",
    "    'Class_NORSE', 'Mg type', 'STESS_5', 'mRS_4', 'Age_65', 'Mg_8.5', 'mRS_Discharge_4', 'Inhospital_Mortality']]\n",
    "\n",
    "feature_mulvar = feature[['Etiology', 'Sz Type']]\n",
    "\n",
    "feature_num = feature[['CIVADs_num', 'AED_number', \n",
    "'Age', 'STESS',  'mRS_premorbid', 'max_Mg_conc', 'Mg_change', 'mRS_Discharge', 'Hospital_days', 'SE_Duration']]\n",
    "\n",
    "results = {}\n",
    "for col in feature_cat.columns:\n",
    "    table = pd.crosstab(feature_cat[col], feature['response_yesnoyes'])\n",
    "    p_value = fisher(table)\n",
    "    results[col] = {'p-value': p_value}\n",
    "\n",
    "for col in feature_mulvar.columns:\n",
    "    table = pd.crosstab(feature_mulvar[col], feature['response_yesnoyes'])\n",
    "    p_value = chisquare(table)\n",
    "    results[col] = {'p-value': p_value}\n",
    "\n",
    "for col in feature_num.columns:\n",
    "    if feature_num[col].isna().sum() != 0:\n",
    "        feature_num2 = feature_num.copy().dropna() \n",
    "        x = feature_num2.loc[feature['response_yesnoyes']==\"y\"][col]\n",
    "        y = feature_num2.loc[feature['response_yesnoyes']==\"n\"][col]\n",
    "        statistics, p_value = stats.mannwhitneyu(x, y)\n",
    "        results[col] = {'p-value': p_value}\n",
    "    else: \n",
    "        x = feature_num.loc[feature['response_yesnoyes']==\"y\"][col]\n",
    "        y = feature_num.loc[feature['response_yesnoyes']==\"n\"][col]\n",
    "        statistics, p_value = stats.mannwhitneyu(x, y)\n",
    "        results[col] = {'p-value': p_value}        \n",
    "\n",
    "result_df1 = pd.DataFrame(results).T\n",
    "\n",
    "results = {}\n",
    "for col in feature_cat.columns:\n",
    "    table = pd.crosstab(feature_cat[col], feature['response_yesnoout'])\n",
    "    p_value = fisher(table)\n",
    "    results[col] = {'p-value': p_value}\n",
    "\n",
    "for col in feature_mulvar.columns:\n",
    "    table = pd.crosstab(feature_mulvar[col], feature['response_yesnoout'])\n",
    "    p_value = chisquare(table)\n",
    "    results[col] = {'p-value': p_value}\n",
    "\n",
    "for col in feature_num.columns:\n",
    "    if feature_num[col].isna().sum() != 0:\n",
    "        feature_num2 = feature_num.copy().dropna() \n",
    "        x = feature_num2.loc[feature['response_yesnoout']==\"y\"][col]\n",
    "        y = feature_num2.loc[feature['response_yesnoout']==\"n\"][col]\n",
    "        statistics, p_value = stats.mannwhitneyu(x, y)\n",
    "        results[col] = {'p-value': p_value}\n",
    "    else: \n",
    "        x = feature_num.loc[feature['response_yesnoout']==\"y\"][col]\n",
    "        y = feature_num.loc[feature['response_yesnoout']==\"n\"][col]\n",
    "        statistics, p_value = stats.mannwhitneyu(x, y)\n",
    "        results[col] = {'p-value': p_value}        \n",
    "\n",
    "result_df2 = pd.DataFrame(results).T\n",
    "\n",
    "result_df = result_df1.join(result_df2, how='inner', lsuffix='_yes_no_to_yes', rsuffix='_yes_no_exclude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import chi2_contingency, fisher_exact\n",
    "\n",
    "# clinical feature\n",
    "feature = pd.read_excel(r\"D:\\주성\\documents\\2025\\Mg comma\\clinical features6.xlsx\", sheet_name = 'Sheet1')\n",
    "feature = feature.iloc[:-2, :]\n",
    "\n",
    "# 파생변수 \n",
    "feature['Immunotherapy'] = ~feature['Immunotherapy Medications'].isna()\n",
    "feature['CIVADs'] = ~feature['CIVAD Medications'].isna()\n",
    "feature['STESS_5'] = feature['STESS'] >= 5\n",
    "feature['mRS_4'] = feature['mRS_premorbid'] >= 4\n",
    "feature['CIVADs_num'] = feature['CIVAD Medications'].apply(lambda x: sum(1 for c in str(x) if c.isupper()) if pd.notna(x) else 0)\n",
    "feature['Age_65'] = feature['Age'] >=65\n",
    "feature['Mg_change'] = feature['max_Mg_conc'] - feature['Mg_baseline']\n",
    "feature['Mg_8.5'] = feature['max_Mg_conc'] >= 8.5\n",
    "feature['mRS_Discharge_4'] = feature['mRS_Discharge'] >= 4\n",
    "\n",
    "# 변수 형태에 따라 나누기\n",
    "feature_cat = feature[['Class_SRSE', 'CIVADs', 'Sex', 'Immunotherapy',\n",
    "    'Class_NORSE', 'Mg type', 'STESS_5', 'mRS_4', 'Age_65', 'Mg_8.5', 'mRS_Discharge_4', 'Inhospital_Mortality']]\n",
    "\n",
    "feature_mulvar = feature[['Etiology', 'Sz Type']]\n",
    "\n",
    "feature_num = feature[['CIVADs_num', 'AED_number', \n",
    "'Age', 'STESS',  'mRS_premorbid', 'max_Mg_conc', 'Mg_change', 'mRS_Discharge', 'Hospital_days', 'SE_Duration']]\n",
    "\n",
    "\n",
    "cross = pd.crosstab(feature_cat['STESS_5'], feature['response'])\n",
    "cross\n",
    "table2x2 = sm.stats.Table2x2(cross)\n",
    "\n",
    "odds_ratio = table2x2.oddsratio\n",
    "odds_ratio_ci = table2x2.oddsratio_confint()\n",
    "\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 예시 2x2 분할표: [[a, b], [c, d]]\n",
    "observed_table = np.array([[2, 10],\n",
    "                           [5, 3]])\n",
    "\n",
    "def compute_odds_ratio(table):\n",
    "    # a, b, c, d\n",
    "    a, b = table[0]\n",
    "    c, d = table[1]\n",
    "    # b나 c가 0이면 계산 시 문제가 발생할 수 있으니, 작은 값(예: 0.5)을 더해 조정할 수 있음\n",
    "    return (a * d) / (b * c) if (b * c) != 0 else np.nan\n",
    "\n",
    "# 부트스트랩 함수\n",
    "def bootstrap_odds_ratio(observed_table, n_bootstrap=10000):\n",
    "    # 원 데이터에 기반해 '개별 관측치'를 재구성합니다.\n",
    "    # 여기서는 각 셀의 값이 빈도를 나타내므로, 각 셀의 값을 해당 빈도만큼의 '사건'으로 재구성\n",
    "    a, b = observed_table[0]\n",
    "    c, d = observed_table[1]\n",
    "    \n",
    "    # 두 변수에 대한 각 관측치를 리스트 형태로 생성\n",
    "    group1 = [1] * a + [0] * b\n",
    "    group2 = [1] * c + [0] * d\n",
    "    \n",
    "    n1 = len(group1)\n",
    "    n2 = len(group2)\n",
    "    \n",
    "    boot_odds = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        sample1 = np.random.choice(group1, size=n1, replace=True)\n",
    "        sample2 = np.random.choice(group2, size=n2, replace=True)\n",
    "        # 재구성된 분할표\n",
    "        a_bs = np.sum(sample1)\n",
    "        b_bs = n1 - a_bs\n",
    "        c_bs = np.sum(sample2)\n",
    "        d_bs = n2 - c_bs\n",
    "        # 만약 0으로 나누는 상황을 피하기 위해서 조정\n",
    "        if b_bs == 0 or c_bs == 0:\n",
    "            continue\n",
    "        table_bs = np.array([[a_bs, b_bs],\n",
    "                             [c_bs, d_bs]])\n",
    "        boot_odds.append(compute_odds_ratio(table_bs))\n",
    "    \n",
    "    boot_odds = np.array(boot_odds)\n",
    "    lower = np.percentile(boot_odds, 2.5)\n",
    "    upper = np.percentile(boot_odds, 97.5)\n",
    "    return np.median(boot_odds), (lower, upper)\n",
    "\n",
    "# 부트스트랩 실행\n",
    "median_or, ci = bootstrap_odds_ratio(observed_table, n_bootstrap=10000)\n",
    "print(f\"부트스트랩 기반 오즈비 중앙값: {median_or:.4f}\")\n",
    "print(f\"부트스트랩 기반 95% 신뢰구간: {ci}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in feature_cat.columns:\n",
    "    print(col)\n",
    "    print(feature_cat[col].unique())\n",
    "    print(feature_cat[col].dtype)\n",
    "    print(pd.crosstab(feature_cat[col], feature['response']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 처리\n",
    "df['mRS_3mo'] = pd.to_numeric(df['mRS_3mo_text'], errors='coerce')\n",
    "df = df.dropna(subset=['mRS_3mo'])\n",
    "\n",
    "# 두 그룹 데이터 추출\n",
    "group1 = df.loc[df['response_10']==True, 'mRS_3mo'].values \n",
    "group2 = df.loc[df['response_10']==False, 'mRS_3mo'].values \n",
    "\n",
    "# Mann-Whitney U 테스트 실행\n",
    "s, p = stats.mannwhitneyu(group1, group2)\n",
    "\n",
    "print(f\"통계량: {s}, p-값: {p}\")\n",
    "\n",
    "# mRS >= 4\n",
    "df['mRS_3mo_4'] = df['mRS_3mo'] >= 4\n",
    "cross = pd.crosstab(df['mRS_3mo_4'], df['response_10'])\n",
    "s, p = stats.fisher_exact(cross)\n",
    "print(f'통계량: {s},  p-값: {p}')\n",
    "\n",
    "# mRS >= 3\n",
    "df['mRS_3mo_3'] = df['mRS_3mo'] >= 3\n",
    "cross = pd.crosstab(df['mRS_3mo_3'], df['response_10'])\n",
    "s, p = stats.fisher_exact(cross)\n",
    "print(f'통계량: {s},  p-값: {p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 타임 포인트에 대한 RM ANOVA (개인 수준의 분석) at Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규성 검정을 일단 하고, ANOVA 및 partial eta-squared와 omega squared를 구해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = [\n",
    "    고정실,김가람,김득실,김영현,김충연,민병춘1,박주연1,\n",
    "    벌,안중훈,윤병시,이미우,임석봉,전창희,\n",
    "    정금례,정용태,이귀임,정복연,김정한,정광훈1,조진욱]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 부분 에타 제곱 계산 함수\n",
    "def partial_eta_squared(f_value, df_effect, df_error):\n",
    "    \"\"\"\n",
    "    계산된 F 값과 자유도로부터 부분 에타 제곱 계산\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    f_value : float\n",
    "        F-통계량 값\n",
    "    df_effect : int\n",
    "        효과(처리)의 자유도\n",
    "    df_error : int\n",
    "        오차의 자유도\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        부분 에타 제곱 값 (0~1 사이)\n",
    "    \"\"\"\n",
    "    return (f_value * df_effect) / (f_value * df_effect + df_error)\n",
    "\n",
    "# Define Cohens'D\n",
    "def cohens_d(group1, group2):\n",
    "    mean1, mean2 = np.mean(group1), np.mean(group2)\n",
    "    std1, std2 = np.std(group1, ddof=1), np.std(group2, ddof=1)\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    pooled_std = np.sqrt(((n1 - 1) * std1**2 + (n2 - 1) * std2**2) / (n1 + n2 - 2))\n",
    "    return (mean1 - mean2) / pooled_std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing large artifact by band 함수 정의\n",
    "def remove_artifacts(before_mean, after_mean, large_artifact):\n",
    "    before_idx = set()\n",
    "    after_idx = set()\n",
    "\n",
    "    for t_start, t_end in large_artifact:\n",
    "        if t_start < 3600 and t_end < 3600:\n",
    "            before_idx.update(range(t_start*200, t_end*200))\n",
    "            after_idx.update(range(t_start*200, t_end*200))\n",
    "        elif t_start < 3600 and t_end >= 3600:\n",
    "            before_idx.update(range(t_start*200, 3600*200))\n",
    "            after_idx.update(range(t_start*200, 3600*200))\n",
    "            after_idx.update(range(0, (t_end-3600)*200))\n",
    "            before_idx.update(range(0, (t_end-3600)*200))\n",
    "        else:\n",
    "            after_idx.update(range((t_start-3600)*200, (t_end-3600)*200))\n",
    "            before_idx.update(range((t_start-3600)*200, (t_end-3600)*200))\n",
    "\n",
    "    before_idx = sorted(before_idx)\n",
    "    after_idx = sorted(after_idx)\n",
    "\n",
    "    return np.delete(before_mean, before_idx), np.delete(after_mean, after_idx)\n",
    "\n",
    "# Process band data 함수 정의\n",
    "def process_band_data(tfr_data, tfr_data_day1, large_artifact):\n",
    "    start1, end1 = 0, 3599 * 200\n",
    "    start2, end2 = 3600 * 200, 7199 * 200\n",
    "\n",
    "    # Split before and after\n",
    "    before = tfr_data[:, :, start1:end1]\n",
    "    after = tfr_data[:, :, start2:end2]\n",
    "    day1 = tfr_data_day1\n",
    "\n",
    "    # Average over channels and frequencies\n",
    "    before_mean_channel = before.mean(axis=0)\n",
    "    after_mean_channel = after.mean(axis=0)\n",
    "    day1_mean_channel = day1.mean(axis=0)\n",
    "    \n",
    "    before_mean = before_mean_channel.mean(axis=0)\n",
    "    after_mean = after_mean_channel.mean(axis=0)\n",
    "    day1_mean = day1_mean_channel.mean(axis=0)\n",
    "\n",
    "    before_clean, after_clean = remove_artifacts(before_mean, after_mean, large_artifact)\n",
    "    day1_clean = day1_mean.copy()\n",
    "    # Remove artifacts\n",
    "    return before_clean, after_clean, day1_clean\n",
    "\n",
    "# Main 함수 정의\n",
    "def main():\n",
    "    # Initialize name dictionary\n",
    "    names = ['고정실', '김가람', '김득실', '김영현', '김충연', '민병춘1', '박주연1', '박주연2', '벌', \n",
    "             '안중훈', '윤병시', '이미우', '임석봉', '전창희', '정광훈2', '정금례', '정용태', '이귀임', \n",
    "             '정복연', '김정한', '정광훈1', '조진욱']\n",
    "    name_dict = {name: i+1 for i, name in enumerate(names)}\n",
    "\n",
    "    # Get analysis targets\n",
    "    name_list = input(\"분석대상 이름을 입력하세요. (여러명일 경우 쉼표로 구분)\").split(',')\n",
    "    print(f'분석대상은 {name_list}입니다.')\n",
    "\n",
    "    ## Load workbook and artifact data\n",
    "    #wb = op.load_workbook(r\"C:\\Users\\esin4\\OneDrive\\바탕 화면\\Github\\Mg_infusion_coma\\Mg_infusion_data.xlsx\")\n",
    "    large_artifact_data = pd.read_csv(r\"C:\\Users\\Brain_Science\\Documents\\GitHub\\Mg_infusion_coma\\large_artifact.csv\", encoding='utf-8-sig')\n",
    "\n",
    "    # Process each name\n",
    "    for name in name_list:\n",
    "        print(f'{name}의 데이터를 분석합니다.')\n",
    "        \n",
    "        # Get large artifacts\n",
    "        large_artifact = []\n",
    "        if name in large_artifact_data['Name'].values:\n",
    "            coordinates = large_artifact_data[large_artifact_data['Name'] == name]['Coordinates'].values[0]\n",
    "            if coordinates != 'skip':\n",
    "                large_artifact = eval(coordinates)\n",
    "        print(f\"{name}의 large artifact: {large_artifact}\")\n",
    "\n",
    "        ## Get row number\n",
    "        #row = name_dict.get(name)\n",
    "        #if row is None:\n",
    "        #    print(f\"{name}이(가) name_dict에 없습니다.\")\n",
    "        #    exit()\n",
    "\n",
    "        # Store band data in dictionary\n",
    "        tfr_data = {}\n",
    "        tfr_data_day1 = {}\n",
    "        \n",
    "        # Load band data\n",
    "        for band in ['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma1', 'Gamma2']:\n",
    "            file_path = rf'E:\\Mg_EEG\\tfr_files_gamma\\{name}{band}_7200_tfr.h5'\n",
    "            file_path_day1 = rf\"E:\\Mg_EEG\\tfr_files_subacute\\{name}_day1_{band}_tfr.h5\"\n",
    "            tfr = mne.time_frequency.read_tfrs(file_path)\n",
    "            tfr_day1 = mne.time_frequency.read_tfrs(file_path_day1)\n",
    "            tfr_data[band] = tfr.data\n",
    "            tfr_data_day1[band] = tfr_day1.data\n",
    "            del tfr, tfr_day1\n",
    "        print(f\"{name}의 데이터를 불러왔습니다.\")\n",
    "\n",
    "        # Combine Gamma bands\n",
    "        if 'Gamma1' in tfr_data and 'Gamma2' in tfr_data:\n",
    "            tfr_data['Gamma'] = np.concatenate([tfr_data['Gamma1'], tfr_data['Gamma2']], axis=1)\n",
    "            del tfr_data['Gamma1'], tfr_data['Gamma2']\n",
    "        if 'Gamma1' in tfr_data_day1 and 'Gamma2' in tfr_data_day1:\n",
    "            tfr_data_day1['Gamma'] = np.concatenate([tfr_data_day1['Gamma1'], tfr_data_day1['Gamma2']], axis=1)\n",
    "        print(f\"{name}의 Gamma1과 Gamma2 데이터를 결합했습니다.\")\n",
    "\n",
    "        # Process each band\n",
    "        for band in ['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma']:\n",
    "            if band not in tfr_data:\n",
    "                print(f\"Warning: {band} data not found\")\n",
    "                exit()\n",
    "                \n",
    "            before_clean, after_clean, day1_clean = process_band_data(tfr_data[band], tfr_data_day1[band], large_artifact)\n",
    "            print(f\"{band} 데이터의 artifact를 제거했습니다.\")\n",
    "            \n",
    "            #run_tests(before_clean, after_clean, band, wb, row, name)\n",
    "            #print(f\"{band} 데이터의 테스트를 실행했습니다.\")\n",
    "            \n",
    "            del tfr_data[band]\n",
    "            print(f\"{band} 데이터를 삭제했습니다.\")\n",
    "        return before_clean, after_clean, day1_clean\n",
    "    ## Save results\n",
    "    #wb.save(r\"C:\\Users\\esin4\\OneDrive\\바탕 화면\\Github\\Mg_infusion_coma\\Mg_infusion_data.xlsx\")\n",
    "    #print(f\"{name_list}의 데이터 분석결과를 저장했습니다.\")\n",
    "    #print(f\"{name_list}의 데이터 분석이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_clean, after_clean, day1_clean = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day1_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in [before_clean, after_clean, day1_clean]:\n",
    "    stat, p = stats.shapiro(group)\n",
    "    print(f\"Shapiro-Wilk Test p-value: {p:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = stats.levene(before_clean, after_clean, day1_clean)\n",
    "print(f\"Levene Test p-value: {p:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# ANOVA 수행\n",
    "f_stat, p_value = stats.f_oneway(before_clean, after_clean, day1_clean)\n",
    "\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# 결과 해석\n",
    "alpha = 0.05  # 유의수준 설정\n",
    "if p_value < alpha:\n",
    "    print(\"유의한 차이가 있음 (귀무가설 기각)\")\n",
    "else:\n",
    "    print(\"그룹 간 평균 차이가 없음 (귀무가설 채택)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# 데이터 준비 (NumPy 배열을 Pandas DataFrame 형태로 변환)\n",
    "data = pd.DataFrame({\n",
    "    'score': np.concatenate([before_clean, after_clean, day1_clean]),\n",
    "    'group': (['before_clean'] * len(before_clean)) +\n",
    "             (['after_clean'] * len(after_clean)) +\n",
    "             (['day1_clean'] * len(day1_clean))\n",
    "})\n",
    "\n",
    "# Tukey's HSD 사후검정 수행\n",
    "tukey_result = pairwise_tukeyhsd(data['score'], data['group'], alpha=0.05)\n",
    "print(tukey_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"E:\\주성\\documents\\2025\\Mg comma\\merged_power_data.xlsx\")\n",
    "\n",
    "# 변화율 계산\n",
    "df['post_change'] = (df['post'] - df['pre']) / df['pre']*100\n",
    "df['day1_change'] = (df['day1'] - df['pre']) / df['pre']*100\n",
    "\n",
    "# relative change 중앙값 및 Q1, Q3\n",
    "print('total')\n",
    "print(df[['post_change', 'day1_change']].describe())\n",
    "for band in df['band'].unique():\n",
    "    print(band)\n",
    "    print(df.loc[df['band']==band][['post_change', 'day1_change']].describe().round(2))\n",
    "\n",
    "# 감소한 수 및 비율\n",
    "print('total')\n",
    "post = print((df['post_change'] < 0).sum())\n",
    "print(post)\n",
    "print(post/100)\n",
    "day1 = print((df['day1_change'] < 0).sum())\n",
    "print(day1)\n",
    "print(day1/100)\n",
    "\n",
    "for band in df['band'].unique():\n",
    "    print(band)\n",
    "     = print((df['post_change'] < 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"D:\\주성\\documents\\2025\\Mg comma\\clinical features6.xlsx\", sheet_name='Sheet1')\n",
    "df = df.iloc[:-2, :]\n",
    "\n",
    "df1 = df[['Mg type', 'mRS_Discharge', 'mRS_3mo_text', 'Inhospital_Mortality', 'SE_Duration', 'Hospital_days']]\n",
    "df1['mRS_Discharge_4'] = df1['mRS_Discharge'] >=4\n",
    "df1['mRS_Discharge_5'] = df1['mRS_Discharge'] >=5\n",
    "\n",
    "for col in ['mRS_Discharge', 'SE_Duration', 'Hospital_days']:\n",
    "    x = df1.loc[df1['Mg type']==1][col]\n",
    "    y = df1.loc[df1['Mg type']==2][col]\n",
    "    s, p = stats.mannwhitneyu(x, y)\n",
    "    print(col, p, x.median(), x.quantile(0.25), x.quantile(0.75), y.median(), y.quantile(0.25), y.quantile(0.75))\n",
    "\n",
    "for col in ['mRS_Discharge_4', 'Inhospital_Mortality', 'mRS_Discharge_5']:\n",
    "    cross = pd.crosstab(df1['Mg type'], df1[col])\n",
    "    s, p = stats.fisher_exact(cross)\n",
    "    print(col, cross, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# 결과를 저장할 빈 리스트 생성\n",
    "results = []\n",
    "\n",
    "# 1부터 20까지 각 임곗값에 대해 반복\n",
    "for time in range(1, 21):\n",
    "    # 각 임곗값별로 새로운 불린 변수 생성\n",
    "    col_time = f'time_{time}'\n",
    "    df2[col_time] = df2['time_until_Mg'] >= time\n",
    "    \n",
    "    # 각 임곗값에 대한 결과를 저장할 딕셔너리 생성\n",
    "    res = {'threshold': time}\n",
    "    \n",
    "    # 연속형 변수 (Mann-Whitney U 검정)\n",
    "    for col in ['mRS_Discharge', 'SE_Duration', 'Hospital_days']:\n",
    "        group_true = df2.loc[df2[col_time] == True, col]\n",
    "        group_false = df2.loc[df2[col_time] == False, col]\n",
    "        \n",
    "        # 두 그룹간의 차이를 검정\n",
    "        try:\n",
    "            s, p_val = stats.mannwhitneyu(group_true, group_false)\n",
    "        except Exception as e:\n",
    "            p_val = np.nan\n",
    "        \n",
    "        # 결과 저장 (p-value, 그룹별 중앙값 등)\n",
    "        res[f'p_{col}'] = p_val\n",
    "        res[f'{col}_median_true'] = group_true.median()\n",
    "        res[f'{col}_median_false'] = group_false.median()\n",
    "        # 추가로 사분위수 등 다른 통계치를 저장할 수도 있음\n",
    "        res[f'{col}_Q1_true'] = group_true.quantile(0.25)\n",
    "        res[f'{col}_Q3_true'] = group_true.quantile(0.75)\n",
    "        res[f'{col}_Q1_false'] = group_false.quantile(0.25)\n",
    "        res[f'{col}_Q3_false'] = group_false.quantile(0.75)\n",
    "    \n",
    "    # 범주형 변수 (Fisher의 정확 검정)\n",
    "    for col in ['mRS_Discharge_4', 'Inhospital_Mortality', 'mRS_Discharge_5']:\n",
    "        cross = pd.crosstab(df2[col_time], df2[col])\n",
    "        try:\n",
    "            # Fisher 검정은 2x2 교차표에 적합하므로, 그렇지 않을 경우 오류가 날 수 있음\n",
    "            s, p_cat = stats.fisher_exact(cross)\n",
    "        except Exception as e:\n",
    "            p_cat = np.nan\n",
    "        res[f'p_{col}'] = p_cat\n",
    "        \n",
    "    # 결과 리스트에 추가\n",
    "    results.append(res)\n",
    "\n",
    "# 결과를 DataFrame으로 변환하여 확인\n",
    "result_df = pd.DataFrame(results)\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(r\"D:\\주성\\documents\\2025\\Mg comma\\result_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.loc[result_df['threshold']==11].T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
